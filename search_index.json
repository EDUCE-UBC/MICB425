[["index.html", "Gene-centric mapping of microbial community structure and function 2020.21 MICB425 Mirobial Ecological Genomics Capstone project Overview", " Gene-centric mapping of microbial community structure and function 2020.21 MICB425 Mirobial Ecological Genomics Capstone project Stephan Koenig, Kim Dill-McFarland, Connor Morgan-Lang, Ryan McLaughlin, Julia Anstett, Resmi Radhamony, Sean Crowe and Steven Hallam version August 12, 2021 Overview This document introduces bioinformatics workflows useful in gene-centric mapping of functional and phylogenetic anchors encoded in microbial genomes sourced from natural and engineered environments. Part I outlines the motivation and insights afforded by the use of these workflows to study uncultivated microbial community structure and function. Part II provides hands-on tutorials to learn two effective tools for gene-centric analysis, TreeSAPP and iTOL. Part III described your capstone project to explore primary metagenomic and metatranscriptomic data collected from the Saanich Inlet water column spanning a defined nutrient and energy gradient. "],["exploring-the-microcosmos.html", "1 Exploring the microcosmos 1.1 Background 1.2 Using multi-omic data to reconstruct distributed networks of metabolite exchange 1.3 TreeSAPP", " 1 Exploring the microcosmos 1.1 Background We live in a world dominated by microbial life. Accounting for bacteria and archaea (prokaryotes) alone, an estimated 1030 cells occupy the biosphere. For most of Earth’s history, this microcosmos has been driving matter and energy transformations through distributed networks of metabolite exchange resulting in global biogeochemical cycles and symbiotic interactions that create and sustain the conditions of multicellular existence, including our own. Recent advances in high-throughput sequencing and mass spectrometry platforms have enabled us to develop more quantitative insights into these networks’ structure and function at the individual, population, and community levels of biological organization. The resulting data sets have revealed both incredible diversity and ecological resilience and provided an opportunity to develop predictive models and sustainable biotechnologies with the potential to transform the way humans interact with the natural world and one another. Despite the power and the promise of this new perception, we exist dangerously close to upsetting the planetary boundaries that have promoted successful human expansion over the past 20,000 years. Global climate change is one manifestation of the cost we have paid in our pursuit of material and energy resources. Still, there are others, including biodiversity loss through habitat destruction, rampant pollution, and imbalances in integral element cycling of nitrogen and phosphorous. Given the increasing availability of data sets describing microbial community structure and function in the world around us, we have an opportunity to learn from this information using bioinformatic tools and approaches. For this course, we will focus on one manifestation of climate change-related to dissolved oxygen (DO) loss in the ocean using a model ecosystem as a source of multi-omic (DNA and RNA) and geochemical parameter information over space and time. Oxygen minimum zones (OMZs) are widespread areas of low DO in subsurface waters. Climate change resulting in increased stratification and reduced oxygen solubility in warming waters leads to OMZ expansion. Consequently, as oxygen levels decline, the microbial communities inhabiting OMZ waters shift their metabolisms to utilize alternative terminal electron acceptors. This shift results in the production of climate-active trace gases such as nitrous oxide (N2O) and methane (CH4). Specifically, we will study the effects of changing oxygen levels on communities of bacteria and archaea inhabiting the Saanich Inlet water column. Saanich Inlet, situated on the coast of Vancouver Island, British Columbia, is a seasonally anoxic fjord that provides a biodynamic perspective on OMZ expansion. From a systems ecology perspective, OMZs provide useful environmental contexts in which to study coupled biogeochemical cycling through distributed metabolic networks, especially the integration of the carbon, nitrogen and sulphur cycles. By combining multi-omics and geochemical parameter information from OMZs, it becomes possible to evaluate microbial communities’ regulatory and response dynamics to changing DO levels. For example, because OMZs are hotspots for nitrogen loss processes reconstructing the nitrogen cycle as a distributed metabolic process can shed new insight into microbial controls on matter and energy transformations integral to ocean health and climate balance. Genes encoding key steps in the nitrogen cycle are well defined (Figure 1.1), providing a basis for functional anchor screening to determine their distribution across the Tree of Life. FIGURE 1.1: Nitrogen cycle 1.2 Using multi-omic data to reconstruct distributed networks of metabolite exchange The nitrogen cycle is just one aspect of the distributed metabolic network that defines microbial interaction space. Throughout this capstone project, you will have the opportunity to explore this space using a gene-centric approach. This approach is based on identifying and quantifying phylogenetic or functional anchor genes that represent key microbial players and metabolic pathways in the system under study. In a big picture sense, we want to use these data to answer three foundational questions concerning microbial community structure and function: Who is there? What are they doing? How do they respond to change? Biological information flow can be described as a process of converting genotypic information encoded in the DNA base pairs of the genome transcribed into RNA messages that are translated into proteins at the level of the ribosome. These proteins, in turn, go on to catalyze metabolic transformations and regulatory dynamics that ultimately give rise to phenotypic expression, adaptation and response. This flow of information is formally referred to as the Central Dogma of Biology. Genomic sequence information provides a basis for determining the types of microorganisms present in a sample and inferring metabolic potential at the individual, population and community levels of biological organization. Because DNA can persist in the environment for longer than RNA or protein, we can also use the abundance of gene X or gene Y to tell us about prior metabolic activity, e.g. gene abundance is a proxy for the process. We can use gene abundance information in numerical models to infer metabolic flux through a given pathway because the abundance of gene X is proportional to genome replication in which it resides. Genomic information is also more robust to sampling noise as we collect and process samples for downstream analysis. For information on gene-centric modelling incorporating DNA, RNA and protein information in Saanich Inlet, see this paper (1). While genomic information tells us about metabolic potential, the transcriptome guides action or gene expression. To a certain extent, we can use this information to identify who is there, but more often, to indicate which pathways are active at the time of sampling. Transcriptomic data can open a window into response patterns along environmental gradients with the caveat that its short-lived nature is less robust to sampling noise. The presence of transcripts for a given gene X is no guarantee for their conversion into protein. However, because prokaryotes couple transcription to translation, we typically infer a direct relationship. For information on relationships between DNA, RNA and protein in Saanich Inlet, see this paper as well (2). 1.3 TreeSAPP For this project, you will be implementing a software application called Tree-based Sensitive and Accurate Protein Profiler (TreeSAPP) (3). Given the current set of reference packages available, you are in a position to reconstruct key steps in selected biogeochemical cycles, e.g. carbon, nitrogen or sulphur, along defined redox gradients in Saanich Inlet. TreeSAPP takes either metagenomic or metatranscriptomic reads and aligns them to reference packages representing phylogenetic or functional anchor genes of interest. These reference packages are constructed from trusted sources and consist of a phylogenetic tree, multiple sequence alignment, hidden Markov model and taxonomic lineage information. Reference packages can be updated and refined as new sequence information becomes available, including isolate reference genomes, metagenome-assembled genomes (MAGs) and single-cell amplified genomes (SAGs), thereby improving the precision of taxonomic placement. TreeSAPP outputs can be readily visualized using the interactive Tree of Life (iTOL) (4) or plotted in R to make beautiful and informative data visualization products. "],["a-tutorial-for-using-treesapp.html", "2 A tutorial for using TreeSAPP 2.1 Introduction and goals 2.2 A typical TreeSAPP workflow 2.3 Genes for creating reference packages 2.4 Tools 2.5 Data", " 2 A tutorial for using TreeSAPP 2.1 Introduction and goals In this series of tutorials, users will analyze a gene family lacking an existing TreeSAPP reference package (refpkg). You will work through a typical workflow of TreeSAPP both with an example gene (XmoA) to familiarize yourself with the tools, and then you will repeat the steps with a gene assigned to your group for which no reference package exists. You will document your efforts for the new reference package in Problem Set 5. 2.2 A typical TreeSAPP workflow Acquiring golden data. Creating a Reference Package For TreeSAPP. Classifying unknown sequences with TreeSAPP and updating a reference package. Calculating relative abundance of meta’omic data. Analysing the TreeSAPP classifications in R. 2.3 Genes for creating reference packages 2.3.1 XmoA The protein family we will be focusing on is that of the copper-containing membrane-bound monooxygenases (5). This family contains particulate methane monooxygenase (pMMO) and ammonia monooxygenase (AMO) and well be building a reference package for the alpha subunits of these enzymes called XmoA. All students will work through this example individually. 2.3.2 Group-assigned genes You will create a reference package and perform the other steps only for the gene that has been assigned to you. RefPkg refpkg_code Full Protein Name Pathway Cycle TIGRFAM PFam EggNOG Other Database EC number Reading cbbS C0003 ribulose bisphosphate carboxylase, type III (Ribulose bisphosphate carboxylase small chain) Carbon fixation C TIGR03326 PF00101 COG4451 NA 4.1.1.39 NA ACoA C0004 ACoA_crb (acetylCoA carboxylase) Carbon fixation C TIGR03182 PF00676 COG1071 NA 1.2.4.1 NA Hzs N0701 hydrazine synthase Annamox N NA PF18582 COG3391 NA 1.7.2.7 https://www.nature.com/articles/nature10453 https://www.frontiersin.org/articles/10.3389/fmars.2019.00027/full NirB N0201 nitrite reductase (NADH) large subunit Dissimilitory nitrate reduction (DNRA) N TIGR02374 NA COG1251 NA 1.7.1.15 NA NirD N0202 nitrite reductase (NADH) small subunit Dissimilitory nitrate reduction (DNRA) N TIGR02378 NA COG2146 NA 1.7.1.15 NA NrfA N0203 nitrite reductase (cytochrome c-552) Dissimilitory nitrate reduction (DNRA) N TIGR03152 NA COG3303 NA 1.7.2.2 NA NrfH N0204 cytochrome c nitrite reductase, small subunit Dissimilitory nitrate reduction (DNRA) N TIGR03153 NA COG3005 NA 1.7.2.2 NA APS_red S0101 adenylylsulfate reductase, thioredoxin dependent Sulfur metabolism S TIGR02055 PF01507 COG1404 NA 1.8.99.2 NA BacRho P0102 Bacteriorhodopsin Energy production and conversion NA NA PF01036 COG5524 NA NA https://science.sciencemag.org/content/289/5486/1902/tab-pdf https://www.nature.com/articles/s41467-018-07840-4 2.4 Tools 2.4.1 Shell Please use this short Shell cheat sheet for commonly used commands and review previous tutorials on Canvas. 2.4.2 TreeSAPP Tree-based Sensitive and Accurate Phylogenetic Profiler (TreeSAPP) (3) can be found on GitHub including an excellent wiki with additional information on each of the treesapp subcommands. 2.4.3 iTOL Interactive Tree Of Life (iTOL) (4) is a browser-based tool that allows you to visualize data generated in TreeSAPP as a phylogenetic tree with additional annotations. 2.5 Data Other than The Saanich Inlet data set already located on the server, you will download data from different databases: FunGene, the functional gene pipeline and repository. EggNOG "],["acquiring-golden-data.html", "3 Acquiring golden data 3.1 The golden standard 3.2 What databases can I retrieve sequences from? 3.3 XmoA example 3.4 Alternative sources 3.5 Data access hazards 3.6 Validation", " 3 Acquiring golden data Golden data in the context of biological sequence analysis are those that come from well-curated open-source databases. These data have been used to create all TreeSAPP reference packages to date, and they should be used to create all future reference packages. But what does “well-curated” mean, and how can you identify data that would meet this gold standard? 3.1 The golden standard The field of genomics is blessed with an abundance of reference data. In fact, it is not uncommon for biologists and bioinformaticians alike to gripe over the increased run-time of computational analyses caused by steps that include comparisons to such large reference databases. Not all of these data are, however, of the same quality. The vast majority have been automatically curated using algorithms with known shortcomings, and only a small portion have been manually curated with verified functional characterization. These latter data are the ones we consider well-curated or golden. More details on choosing databases for retrieving sequences can be found on the TreeSAPP wiki. 3.2 What databases can I retrieve sequences from? One of the most comprehensive and reputable biological sequence databases is SwissProt. The protein sequences curated within SwissProt can be accessed and downloaded through the UniProt Knowledgebase by selecting “Swiss-Prot” under the “UniProtKB” panel on the left of the landing page. You can submit queries for a protein family through their search bar and add filters to the query using their advanced search options. For example, you can search for reviewed RuBisCO sequences by entering the query ‘rubisco taxonomy:“Bacteria [2]” AND reviewed:yes’. Throughout the development of TreeSAPP, I have frequented FunGene, the functional gene pipeline and repository. This database provides curated sequences (of varying reliability) for many popular functional and taxonomic anchor genes. FunGene is also great since they have profile hidden Markov models (HMMs) for every gene available. In bioinformatics, HMMs are commonly used to represent a group of homologous amino acid sequences, often belonging to the same protein family, as a probabilistic model. They are inferred by modelling the amino acid character frequencies and motifs along the length of multiple aligned sequences. Additionally, by providing a sense of the full-length protein, they allow users to filter the sequences based on the percentage of an HMM covered. Since we’re building a reference tree, only include roughly full-length sequences by setting that minimum HMM coverage parameter between 60 and 90%. EggNOG is another source of curated orthologous groups. The breadth of families available here is astounding and more often than not they do have the sequences you’re looking for. There are a couple of benefits to accessing data from EggNOG. The first is they use a common identifier format. Using the correct identifier for a protein family, a single search will yield all available amino acid sequences belonging to that protein family or COG. What I’ve found handy is first looking for the Clusters of Orthologous Gene (COG) identifier on NCBI’s Conserved Domains database. Then I’d use that identifier to search for the sequences I’m interested in on EggNOG. The second benefit is the quality of their automated annotation pipeline. With every version of EggNOG, the entire set of protein sequences is clustered and the orthologous groups are defined de novo. This prevents incorrect legacy annotations from propagating to new sequences. Unfortunately, the breadth of taxa covered by EggNOG is limited to just 5,090 organisms. In many cases, this is good enough to build a “seed” reference package, especially if you’re building a reference package of a well-conserved—or housekeeping—gene. Yet, there are plenty of scenarios where the number of sequences downloaded is just too few for your objective, and a more comprehensive reference package is required—more on that below. In addition to these general and all-encompassing databases, there are smaller curated databases that are independently maintained. These tend to be gene- or function-specific and, as long as they’re still maintained, highly reliable. Perhaps the most notable of these is the Carbohydrate Active enZYmes (CAZy) database. The maintainers of CAZy constantly screen new sequenced from GenBank and sort any hits into different families based on their putative biochemical characterization. 3.3 XmoA example To show you how to access these data, we will download the alpha subunit sequences of the enzymes particulate methane monooxygenase (PmoA) and ammonia monooxygenase (AmoA) that are used in the treesapp create tutorial from the FunGene and EggNOG databases. 3.3.1 FunGene First, navigate to http://fungene.cme.msu.edu/. This front page organizes the genes into their respective functional groups. The sequences we’re interested in are involved in biogeochemical cycling, so look under that panel for “AmoA” and “PmoA”. As you can see, AmoA are broken up into four different entries: “amoA_AOA”, “amoA_AOB”, “amoA_AOB_like”, and “amoA_comammox”. We will download the sequences from only “amoA_AOA” and “amoA_AOB”, so let’s begin alphabetically with “amoA_AOA”. For these sequences, we will limit them to just sequences derived from isolate genomes of which the functional and taxonomic annotations are more reliable. To do this, go to “Display Options” in the top right. Click the “Isolate” option then “Update”. We also want the sequences that are more-or-less full-length. Click on “Show/Hide filter options”, fill the “Minimum HMM Coverage” parameter with “80” (or some other number between 60 and 90), then “Filter”. That’s all the filtering we’re going to do here. To add the sequences to your cart, click “Select All Sequences” then “Begin Analysis”. Deselect “Aligned” then click the “Download” button. Repeat with the above steps with the other genes “amoA_AOB” and “PmoA”. 3.3.2 EggNOG Go to the EggNOG website at http://eggnog5.embl.de/#/app/home and search for either “ENOG5028JPK” or “arCOG08676” in the search bar at the top of the page. These EggNOG ortholog identifiers correspond to PmoA/AmoA from Bacteria and AmoA from Archaea, respectively. In the image below, we’ve searched for “ENOG5028JPK”. Click “Download” at the bottom-left of the panel and select “All XX sequences (FASTA)”, where XX is the number of sequences belonging to the orthologous group (OG). This will open a new window with all sequences from that OG in FASTA format. Download this file to a file on your computer following the format &lt;OG name&gt;_EggNOGv5.faa where &lt;OG name&gt; is the EggNOG ortholog identifier. Repeat the above steps with the other EggNOG identifier. 3.3.3 Copying data onto the server On your computer: Create a new directory called Xmoa_sequences inside of your home directory by using a file browser, i.e. File Explorer (Windows 10) or Finder (macOS). Place any reference sequences in Xmoa_sequences that you identified and downloaded from the databases. Next, connect to your personal server using the terminal app, i.e. Windows Terminal (Windows 10) or Terminal (macOS). ssh root@&lt;server address&gt; On the server: Move to the directory /data (if it is not your working directory already), create a new directory called ts_tutorial and then move into it. cd /data/ mkdir ts_tutorial cd ts_tutorial On your computer: Open a second terminal window that is connected to your local computer, then copy the reference sequences from your computer to your server. scp -r &lt;path to Xmoa_sequences&gt; root@&lt;server address&gt;:/data/ts_tutorial 3.4 Alternative sources EggNOG and FunGene are my favourite sources, though this leaves out the majority of biological sequence databases for no reason other than simplicity. IMG, KEGG, PFam, and other similar databases are all great but they lack an API to retrieve lineage information, and therefore this needs to be provided in a separate table. Details on this table’s format and how to provide it can be found under the treesapp create wiki page. 3.5 Data access hazards Accessing the fraction of well-curated data from multiple databases is not trivial. Perhaps the most obvious reason for this are unrelated genes with shared names. For example, the gene product of mcrB in E. coli widely refers to 5-methylcytosine-specific restriction enzyme B, but in the Archaea, it would refer to the beta subunit of methyl-coenzyme M reductase—a completely unrelated protein. This is an inevitability in a field of science as broad as biology, where scientists that are responsible for naming genes cannot possibly be aware of all gene names in circulation. Another issue can be genes or proteins with synonyms, making the search for these data more complex. In these cases, you may need to search multiple databases with several queries in order to access all the sequences belonging to the same protein family. 3.6 Validation There are a number of quality control measures that can be taken to ensure the functional characteristics are as expected. 3.6.1 Basic BLAST: The first method for validating a set of candidate reference sequences could be to use the web-based Basic Local Alignment Search Tool available through the NCBI. Submit a FASTA file containing your sequences to Protein BLAST (blastp) with an appropriate database. To further reduce the processing time, you can restrict the reference sequences to specific taxa or use different algorithms. One thing to note is the query size limit - blastp will accept only FASTA files containing fewer than 100,000 characters. So, it is a good idea to take a representative sample or cluster the sequences before submitting the job. EggNOG-mapper: If you didn’t download your query sequences from the EggNOG database, a good resource to check your sequences is EggNOG mapper. It will annotate your query sequences against the EggNOG database and serve the result in several formats. 3.6.2 Advanced Phylogenetic inference: Try building a phylogeny from the candidate reference sequences and see whether there are any anomolously long branches between clades. hmmsearch across PFam database: Got some time to kill? Try aligning your candidate reference sequences to all profile HMMs in the PFam database! This will need to be done on the command-line and you will need to download Pfam-A.hmm.gz from the PFam ftp site. "],["treesapp-create.html", "4 Creating a reference package for TreeSAPP 4.1 Introduction and goals 4.2 Making the reference package 4.3 Testing the purity of the reference package 4.4 Viewing the reference package tree with iTOL 4.5 Building your group’s reference package", " 4 Creating a reference package for TreeSAPP 4.1 Introduction and goals In this tutorial we will demonstrate how to build a TreeSAPP reference package and assess whether there are any mis-annotated in the final product. The goals of this tutorial are: To learn how to use treesapp create to build a reference package for a simple protein family (XmoA) using the sequences acquired in the previous tutorial Learn how to assess whether the reference package contains only homologous sequences using treesapp purity Learn how to view a reference package’s phylogenetic tree using the interactive Tree of Life (iTOL) 4.2 Making the reference package In the Acquiring golden data tutorial, PmoA &amp; AmoA sequences were downloaded from TIGRFAM, EggNOG, and FunGene. For now we’ll just use the TIGRFAM seed sequences and EggNOG sequences as these are best curated. Let’s call this our seed reference package. The steps involved are: All steps are executed on the server unless stated otherwise!! Connect to your personal server and continue to work in the /data/ts_tutorial directory. cd /data/ts_tutorial Optional: If you could not download the reference sequences of XmoA yourself (see Acquiring golden data), download xmoa_file_list.txt—a list of the necessary fasta files—with wget to the ts_tutorial directory, then run wget again to retrieve each file within this list. cd /data/ts_tutorial wget https://raw.githubusercontent.com/hallamlab/TreeSAPP/master/docs/xmoa_file_list.txt wget -i xmoa_file_list.txt Create the input FASTA file by combining the EggNOG and TIGRFAM reference into a single file using cat. cat stands for concatentate, i.e. the files are pasted together. The output of cat is funneled with the &gt; symbol to a &lt;new file&gt;, i.e. cat &lt;file 1&gt; &lt;file 2&gt; &gt; &lt;new file&gt; cat ENOG5028JPK_EggNOGv5.faa TIGR03080.faa arCOG08676_EggNOGv5.faa &gt; XmoA_seed.faa There are 76 well curated PmoA and AmoA fasta sequences in this file. Let’s look briefly at the newly generated fasta file. less XmoA_seed.faa You will notice, that they are lines that start with a &gt; that gives the name of a sequence followed by a line containing the actual nucleotide sequence itself. We can count and confirm the number of sequences in the fasta file by counting those &gt; using grep. grep is an incredibly powerful tool to find matching text patterns (using a format called “regular expression”) and is beyond the scope of this tutorial. The code below searches for a &gt; at the beginning of the line (defined with \"^&gt;\") of the file XmoA_seed.faa and counts each occurrence due to the option -c. grep -c &quot;^&gt;&quot; XmoA_seed.faa Use submodule treesapp create to build the XmoA reference package with different arguments (see visualization of the create workflow). To speed things along, we will use FastTree to infer the phylogeny and will skip bootstrapping with --fast. To remove potential redundant sequences, we will cluster the candidate reference sequences at 97% similarity using the argument -p. When clustering the candidate sequences TreeSAPP would normally ask which sequence to use for the representative of the cluster. This can be handy in cases when some sequences are better annotated and/or are especially important. To speed things up even more, the flag --headless will prevent these requests. This command will take ~2 minutes to complete. treesapp create \\ --fast \\ --headless \\ --overwrite \\ --cluster \\ --trim_align \\ -n 4 \\ -m prot \\ -p 0.97 \\ --fastx_input XmoA_seed.faa \\ -c XmoA \\ --output XmoA_seed The final reference package file is located in XmoA_seed/final_outputs/XmoA_build.pkl. This file contains all the individual components of a reference package (multiple sequence alignment, profile HMM, phylogenetic tree, taxonomic lineages) as well as some other data. These files were bundled up using the joblib Python library. They can be accessed individually using the submodule treesapp package. Replace the current refpkg_code Z1111 with unique identifier N0102. treesapp package edit \\ refpkg_code N0102 \\ --overwrite \\ --refpkg_path XmoA_seed/final_outputs/XmoA_build.pkl We can also modify the reference package’s description while we’re here. treesapp package edit \\ description &quot;Alpha subunits of copper membrane monooxygenase enzymes&quot; \\ --overwrite \\ --refpkg_path XmoA_seed/final_outputs/XmoA_build.pkl 4.3 Testing the purity of the reference package We will determine whether there were any mis-annotated sequences that were included in our reference package with treesapp purity. To do this, we take a well-curated database and attempt to classify sequences in it using treesapp assign. The results are then analysed and displayed for the user to evaluate. The TIGRFAM database is fairly comprehensive, representing 4488 different groups in version 15, and by using just the TIGRFAM seed sequences (TIGRFAM_seed_named.faa) we can be fairly sure we won’t be evaluating our classifications with mis-annotated sequences. treesapp purity \\ --trim_align \\ -m prot \\ -n 4 \\ -r XmoA_seed/final_outputs/XmoA_build.pkl \\ --extra_info TIGRFAM_info.tsv \\ -i TIGRFAM_seed_named.faa \\ --output XmoA_purity The important bit of the output should look like this Summarizing assignments for reference package XmoA Ortholog Hits Leaves Tree-coverage Description -------------------------------------------------------------------------------- TIGR03080 3 4 11.1 methane monooxygenase/ammonia monooxygenase, subunit A From this summary it appears that the reference package classified three homologous sequences that were placed at leaf nodes in the tree (i.e. they’re closely related) and the sequences were all from the family “TIGR03080”, also known as “methane monooxygenase/ammonia monooxygenase, subunit A”. In all, we are probably good to proceed! 4.4 Viewing the reference package tree with iTOL We have now created a phylogenetic tree for XmoA, but if we would visualize it, we would only see TreeSAPP identifiers (such as 1_XmoA, 2_XmoA) as labels on the tree which by themselves are not meaningful. In order to assign leaf labels to the refpkg iTOL tree, we will use the treesapp assign function. Assign reference sequences to reference package to generate tree with labels. treesapp assign \\ -n 4 \\ -m prot \\ --trim_align \\ --refpkg_dir XmoA_seed/final_outputs/ \\ --fastx_input XmoA_seed.faa \\ --output XmoA_seed_assign/ The treesapp assign output directory (defined by the flag --output, i.e. in this case XmoA_seed_assign) contains the iTOL_output directory. On your computer: Transfer XmoA_seed_assign/iTOL_output from the server to your local directory Xmoa_sequences. scp -r root@&lt;server address&gt;:/data/ts_tutorial/XmoA_seed_assign/iTOL_output &lt;path to Xmoa_sequences&gt; We can quickly and easily view the sequences placed on the phylogeny using iTOL. We will do this by uploading the JPlace file produced by TreeSAPP. This JPlace file contains both the phylogeny and the location of the placements that will be visualized. Navigate to https://itol.embl.de/ using a web browser and sign in using the group’s username and password. Upload the file XmoA_complete_profile.jplace. You can do this using either your computer’s file browser then navigating to the iTOL_output directory and clicking-and-dragging the file, or iTOL’s file uploader—the “Upload tree files” button. Next, navigate to the page displaying the phylogeny and click-and-drag the file XmoA_labels.txt from your file browser into the iTOL window. This should convert the TreeSAPP identifiers (e.g. 1_XmoA) to more useful descriptions with the organism name and accession for each leaf node. Finally, turn on the “Phylogenetic Placements” dataset (right of the screen) and the figure should look identical to this figure below Figure 4.1. FIGURE 4.1: Phylogenetic tree of XmoA_seed refpkg. The red bubbles represent sequence placements with the size of the bubble indicating the number of placements on a branch. 76 sequences were classified and placed on 36 leaf nodes. 4.5 Building your group’s reference package Now we have covered the first steps of creating a reference package for TreeSAPP and visualizing the outputs. Adapt and repeat the steps for Acquiring golden data and creating the reference package (this chapter) for the gene assigned to your group using your group’s server. On your computer: create a directory &lt;gene_name_sequences&gt; in your home directory and download any reference sequences for your gene you can find on the databases. On the server: In the directory /data, create a new directory &lt;gene name&gt;. On your computer: Copy the reference sequences from your computer to the directory /data/&lt;gene name&gt; on the server. On the server: Work in /data/&lt;gene name&gt; as you are creating your TreeSAPP referenc package and outputs. On your computer: Whenever you have TreeSAPP outputs that can be visualized with iTOL, copy the files from the server to your computer to do so. 4.5.1 Booster shot The reference package for XmoA is relatively small, and ideal for an in-class tutorial. However, many protein families are much more complex with members spread broadly across the tree of life. In these cases, you may need to use other tactics to reduce the size of your reference package so treesapp create can finish in under a few hours. Using any or all of the following options are not required, but may be useful. Remove more candidate reference sequences from the final reference package by decreasing the percent similarity used during sequence clustering. In the tutorial we set “-p”/“--similarity” to 0.97 but this is going to be too high in many cases. Try something between 0.80 and 0.95 to get between 100 and 2000 sequences. A profile HMM can be used to accomplish two things: first it can be used to remove sequences with only remote homology to the protein family you’re building a reference package for; second, each HMM alignment can be used to trim the input sequences to just the conserved regions improving the quality of the multiple sequence alignment and phylogeny. You can download a profile HMM from EggNOG by going to your gene’s EggNOG page, clicking Download ᐁ and then “HMM model”. This will typically only be available for subgroups such as “Bacteria”, “Archaea”, “Proteobacteria”, etc. (i.e. not ‘root’). Provide the HMM file to treesapp create with the “--profile” argument. Metagenomic data from Saanich Inlet were generated from biomass where larger Eukaryotic cells had been physically removed prior to sequencing. Therefore, these organisms do not need to be present in the reference packages. You can remove sequences that are Eukaryotic in origin by using either “--screen” or “--filter” arguments. For example, to only include Bacteria and Archaea use --screen Bacteria,Archaea or --filter Eukaryota. The “--min_taxonomic_rank” argument specifies the minimum taxonomic rank a sequence’s taxonomic lineage must be resolved to. For example, using --min_taxonomic_rank g will ensure that all sequences in the reference package have been annotated to the genus, species or strain taxonomic rank. To specify others ranks , use the lowercase first letter of that taxonomic rank. If your reference package is still very large after using the above options, setting this argument to a highly resolved taxonomic rank can be a potent way to remove candidate reference sequences. To bring all of these arguments together for you here is an example command: treesapp create --fast \\ --headless \\ --overwrite \\ --cluster \\ --trim_align \\ -n 4 \\ -m prot \\ --similarity 0.90 \\ --screen Bacteria,Archaea \\ --min_taxonomic_rank g \\ --profile arCOG08676_hmm.txt \\ --fastx_input XmoA_seed.faa \\ -c XmoA \\ --output XmoA_seed "],["classifying-unknown-sequences-with-treesapp-and-updating-a-reference-package.html", "5 Classifying unknown sequences with TreeSAPP and updating a reference package 5.1 Introduction and goals 5.2 Change notes 5.3 Classify new sequences 5.4 Update the reference package with new sequences 5.5 Annotate clades 5.6 Reclassify and layer annotations onto classification table 5.7 Use your group’s reference package to classify unkown sequences then update your package", " 5 Classifying unknown sequences with TreeSAPP and updating a reference package 5.1 Introduction and goals We will be using the new particulate methane monooxygenase (pMMO) and ammonia monooxygenase (AMO) alpha subunit, or XmoA, reference package and update it with XmoA amino acid sequences sourced from FunGene. You already created the reference package (Creating a Reference Package For TreeSAPP) and downloaded the sequences (Acquiring golden data). There are three goals of this tutorial: Learn how to update a TreeSAPP reference package with treesapp update. Learn how to use treesapp colour to colour a phylogeny in iTOL. Learn how to annotate features of phylogenetic clades using treesapp layer. The first step involves using treesapp assign to classify the FunGene XmoA sequences. The second step is to use treesapp update to add the new sequences to the original XmoA reference package. 5.2 Change notes With TreeSAPP version 0.10.4, treesapp update no longer automatically retrains the reference package. Therefore, it doesn’t require a FASTA file and the commands have been updated to reflect this change. This will save a significant amount of time! 5.3 Classify new sequences Before we can begin using TreeSAPP, we must log onto the server and make sure we’re in the same directory as all our data. cd /data/ts_tutorial/ According to treesapp purity in the last chapter, and all other sanity checks, the XmoA reference package (contained in your working directory, /data/ts_tutorial, at XmoA_seed/final_outputs/XmoA_build.pkl) looks functional and only contains XmoA sequences. At this point, you’re able to use this reference package to classify sequences in any dataset using treesapp assign. The command treesapp assign is perhaps the most popular command and is described in detail on the TreeSAPP wiki. For these commands we will use Block Mapping and Gathering with Entropy (BMGE) which filters out regions of questionable homology from the alignment (6). Please see the BMGE publication for more information. To trim the multiple sequence alignments prior to phylogenetic placement use the --trim_align flag. To use the PmoA and AmoA reference package we’ve built instead of any other reference packages that come with TreeSAPP we can use the argument --refpkg_dir with the path to a directory containing reference packages we want to use. As usual, if you’re unclear as to what any arguments are, you can use treesapp assign -h to get the complete usage and descriptions of each argument. 5.3.1 Classifying amino acid sequences We’re first going to classify PmoA and AmoA sequences sourced from FunGene. The sequences are from genomes of isolated bacteria and archaea and, because of FunGene’s quality annotation pipeline, can likely be trusted. Environmental sequences (i.e. those from metagenomes and amplicon studies) have been excluded as they’re more difficult to determine what organism they’re from, and so the taxonomic labels are less trustworthy. treesapp assign \\ -n 4 \\ -m prot \\ --trim_align \\ --refpkg_dir XmoA_seed/final_outputs/ \\ --fastx_input p_amoA_FunGene9.5_isolates_C65S300_uclust99.faa \\ --output p_amoA_FunGene9.5_isolates_assign/ The command should take a few seconds to run and if you see a ‘TreeSAPP has finished successfully.’ at the end then you’re good to move on. 5.3.2 Classifying ORFs predicted from genomes The second batch of sequences that we will classify XmoA from are metagenome-assembled genomes (MAGs). MAGs are derived from assembled metagenome datasets (i.e. contigs or scaffolds) and represent the genome of a closely related microbial population. You can think of them as representing a single strain present in a microbial community. We will need to download two files: the FASTA file containing the genomes and a table with the taxonomic label for each genome. wget https://raw.githubusercontent.com/EDUCE-UBC/MICB425/main/data/SI072_MAGs.fa ./ wget https://raw.githubusercontent.com/EDUCE-UBC/MICB425/main/data/SI072_MAGs_gtdbtk.bac120.summary.tsv ./ The first file was created by concatenating twelve different MAGs into a single file and prepending each sequence name (i.e. header) with the MAG name using the software seqkit. Concatenating multiple genomes into a single file saves time since you only need to run treesapp assign once instead of classifying each MAG individually. Prepending the header with its respective MAG name is necessary to properly map the names of the query sequences back to their original genome names during the update process. Here is the shell command used (do not run): for f in *fa do mag_name=$( basename $f | sed &#39;s/.fa//g&#39; ) cat $f | seqkit replace -p &quot;^&quot; -r &quot;${mag_name}_&quot; &gt;&gt;SI072_MAGs.fa done The treesapp assign command we use is very similar from those we’ve used in the past. The main difference is we do not need to include -m prot as TreeSAPP assumes the input is comprised of nucleotide sequences by default. treesapp assign \\ -n 4 \\ --trim_align \\ --refpkg_dir XmoA_seed/final_outputs/ \\ --fastx_input SI072_MAGs.fa \\ --output SI072_MAGs_assign/ This command should take less than a minute to complete. 5.4 Update the reference package with new sequences The initial XmoA_seed reference package was pretty small with just 36 sequences (information was retrieved using treesapp package view num_seqs -r XmoA_seed/final_outputs/XmoA_build.pkl). Also, there were only bacterial sequences included in this version and we know there are archaeal ammonia oxidizers too. Let’s see if we can expand on this seed reference package using the sequences from FunGene. 5.4.1 Updating with publicly available sequences You have already seen many of these flags and arguments before, and they’re used again here just to remind TreeSAPP that we want results fast. A couple of new ones are used, though. treesapp update won’t take just any old FASTA file but relies on the outputs produced by treesapp assign. So we’ll guide it to the relevant output directory with --treesapp_output p_amoA_FunGene9.5_isolates_assign/. From there, it will figure out what sequences were classified and what their assigned lineages were. By default TreeSAPP will use the lineage that was assigned to each classified query sequence from the treesapp assign outputs. Since these sequences are from FunGene (and originally GenBank) they have NCBI accessions, meaning we can use this information to download their true taxonomic lineages. To turn on that behaviour we use the --skip_assign flag. Lastly, we must give it the path to the reference package to update with --refpkg_path XmoA_seed/final_outputs/XmoA_build.pkl. NOTE: --fastx_input XmoA_seed.faa has been removed from all treesapp update commands as of TreeSAPP 0.10.4 being installed on the server. See above for more details. treesapp update \\ --fast \\ --headless \\ --overwrite \\ --delete \\ --cluster \\ --trim_align \\ -n 4 \\ -m prot \\ --output XmoA_FunGene_update/ \\ --skip_assign \\ --treesapp_output p_amoA_FunGene9.5_isolates_assign/ \\ --refpkg_path XmoA_seed/final_outputs/XmoA_build.pkl It looks like 28 new sequences were introduced into the reference package, bringing the total to 63 sequences! And judging from the taxonomic rank summary printed during runtime both Archaea and Bacteria are now included: Number of unique lineages: root 1 domain 2 phylum 5 class 6 order 10 family 13 genus 25 species 38 5.4.2 Updating with MAG sequences We are now going to update the reference package that we just updated using the MAG sequences to demonstrate how to iteratively update reference packages. A key difference between using sequences accessioned in the NCBI and here is we must provide the taxonomic labels for each MAG. The MAGs were assigned taxonomic labels using the Genome Taxonomy Database toolkit (GTDB-tk)(7). We first need to reformat the table containing the taxonomic labels of the MAGs. We will employ the shell functions awk and sed to pull out the two columns we need and find-and-replace words and characters. awk -F&quot;\\t&quot; &#39;{ OFS=&quot;\\t&quot;; print $1,$2 }&#39; SI072_MAGs_gtdbtk.bac120.summary.tsv | \\ sed &#39;s/user_genome/Organism/g&#39; | \\ sed &#39;s/classification/Lineage/g&#39; | \\ sed &#39;s/;/; /g&#39; &gt;gtdb_classifications.tsv Now that we have everything we need we can proceed to run treesapp update to add the MAG sequences to the reference package. treesapp update \\ --fast \\ --headless \\ --overwrite \\ --delete \\ --cluster \\ --trim_align \\ -n 4 \\ -m prot \\ --output XmoA_MAG_update/ \\ --skip_assign \\ --seqs2lineage gtdb_classifications.tsv \\ --treesapp_output SI072_MAGs_assign/ \\ --refpkg_path XmoA_FunGene_update/final_outputs/XmoA_build.pkl One of the XmoA sequences from the MAGs should have been added to the reference package bringing the total to 64 reference sequences. A summary of the reference package will have been printed to the screen if treesapp update completed properly, and it should look like this: Summary of the updated reference package: ReferencePackage instance of XmoA (N0102): Molecule type: &#39;prot&#39; TreeSAPP version: &#39;0.10.1&#39; Profile HMM length: &#39;247&#39; Substitution model used for phylogenetic inference: &#39;LG+G4&#39; Number of reference sequences (leaf nodes): 64 Software used to infer phylogeny: &#39;FastTree&#39; Date of last update: &#39;2021-03-22&#39; Description: &#39;Alpha subunits of copper membrane monooxygenase enzymes&#39; For supplementary reading on how to integrate sequences from SAGs and MAGs into reference packages please visit the TreeSAPP Wiki. Just to finish this off, let’s map the PmoA and AmoA sequences from FunGene onto the MAG-updated reference package with treesapp assign to view later. treesapp assign \\ -n 4 \\ -m prot \\ --trim_align \\ --refpkg_dir XmoA_MAG_update/final_outputs/ \\ --fastx_input p_amoA_FunGene9.5_isolates_C65S300_uclust99.faa \\ --output p_amoA_FunGene9.5_isolates_update_assign/ 5.5 Annotate clades Protein families vary in their evolutionary complexity; many, especially genes involved in scavenging and metabolizing nutrients, have often been involved in some gene duplication and/or lateral gene transfer event while others have remained anchored to their host. Moreover, closely related enzymes can vary in their activities and it is often valuable, though not necessary, to annotate such features. Creating your own annotations involves scouring the literature to identify the phenotypes associated with each organism or taxon. For example, you would need to determine what paralogs or substrates are used by each organism in the reference package. Often though, these phenotypes are conserved across larger taxonomic groups, such as whole genera, families, orders, etc. If you are not familiar with the evolution of a protein family it may be helpful to find reference sequences for the activity, function, or other feature you’re interested in and place them on the tree with treesapp assign. Then, guided by these sequences, it should be easier to annotate the clades. Seeing as a literature review can’t be accomplished within the time span of this tutorial, you can use the annotations already created for the XmoA reference package. wget https://raw.githubusercontent.com/hallamlab/RefPkgs/master/Nitrogen_metabolism/Nitrification/XmoA/XmoA_taxonomy-phenotype_map.tsv You can view the contents of this file with the Unix command less: less XmoA_taxonomy-phenotype_map.tsv d__Archaea AmoA_AOA Methylococcaceae EmoA g__Haliea EmoA f__Nitrosomonadaceae AmoA_AOB o__Chromatiales AmoA_AOB g__Methylobacter PmoA g__Methylacidiphilum PmoA To create a file compatible with iTOL you will need to convert the taxonomy-phenotype mapping file with treesapp colour. treesapp colour \\ -r XmoA_MAG_update/final_outputs/XmoA_build.pkl \\ -o XmoA_colours/ \\ -n Function \\ --taxa_map XmoA_taxonomy-phenotype_map.tsv The two output files—XmoA_Function_colours_style.txt and XmoA_Function_colour_strip.txt—can be used to bring colour to the JPlace file in iTOL and also be used for adding phenotype-level annotations to the classification table with treesapp layer. Let’s make copies of the two text files in XmoA_colours/ into the AmoA_assign/iTOL output directory and transfer them to &lt;path to Xmoa_sequences&gt;. cp -r XmoA_colours p_amoA_FunGene9.5_isolates_update_assign/iTOL_output/ On your computer: Transfer XmoA_seed_assign/iTOL_output from the server to your local directory Xmoa_sequences. scp -r root@&lt;server address&gt;:/data/ts_tutorial/p_amoA_FunGene9.5_isolates_update_assign/iTOL_output &lt;path to Xmoa_sequences&gt; Navigate to https://itol.embl.de/ using a web browser and sign in using the group’s username and password. Upload the file XmoA_complete_profile.jplace. You can do this using either your computer’s file browser then navigating to the iTOL_output directory and clicking-and-dragging the file, or iTOL’s file uploader—the “Upload tree files” button. Next, navigate to the page displaying the phylogeny and click-and-drag the file XmoA_labels.txt from your file browser into the iTOL window. This should convert the TreeSAPP identifiers (e.g. 1_XmoA) to more useful descriptions with the organism name and accession for each leaf node. The two files XmoA_Function_colours_style.txt and XmoA_Function_colour_strip.txt can be dragged into the iTOL browser window to bring colour to the XmoA tree. The figure should look identical to Figure 5.1 FIGURE 5.1: XmoA phylogeny after functional annotation Finally, turn on the “Phylogenetic Placements” dataset (right of the screen). 5.6 Reclassify and layer annotations onto classification table With the clade colours file in the tutorial directory, it is now simple to assign each of the classified query sequences to its respective functional guild with treesapp layer. treesapp layer \\ --colours_style XmoA_colours/XmoA_Function_colours_style.txt \\ --refpkg_dir XmoA_MAG_update/final_outputs/ \\ --treesapp_output p_amoA_FunGene9.5_isolates_update_assign/ The output of this command is p_amoA_FunGene9.5_isolates_update_assign/final_outputs/extra_annotated_marker_contig_map.tsv. It contains an extra column for the functional annotations but is otherwise identical to the original marker_contig_map.tsv file. You can view the first 10 lines by using the Unix command head: head p_amoA_FunGene9.5_isolates_update_assign/final_outputs/extra_annotated_marker_contig_map.tsv 5.7 Use your group’s reference package to classify unkown sequences then update your package Continue to work with your group’s reference package in the directory /data/&lt;gene name&gt;. Visualize the appropriate outputs with iTOL. "],["calculating-relative-abundance-of-metaomic-data.html", "6 Calculating relative abundance of meta’omic data 6.1 Introduction and goals 6.2 Workflow description 6.3 Usage 6.4 Outputs 6.5 Tutorial steps 6.6 Use your group’s reference package to calculate abundances", " 6 Calculating relative abundance of meta’omic data 6.1 Introduction and goals Genome assemblies contain less information than the sequence reads and recovering it is not always possible. The shotgun DNA sequencing technique samples subsequences from the genomes that comprise a microbial community. Sequencing bias, while present, is subtle enough that we can assume that each subsequence’s frequency in the reads approximates its abundance in the underlying community. Whenever a (meta)genome is assembled from reads, however, sequences that are tricky to assemble (due to repetitive motifs or low coverage) are removed and the abundance information is effectively lost. One way to recover these read-level abundances is by aligning the reads back to the contigs and calculating the number of reads that mapped to each. One can go a step further still and use relative abundance normalization measures popular in transcriptomics, such as fragments per kilobase per million mappable reads (FPKM) or transcripts per million (TPM) (8). TreeSAPP’s subcommand abundance is capable of calculating FPKM or TPM for all classified query sequences. These can be derived from the reads in the FASTQ files of multiple different samples. This is only possible when the input fasta are nucleotide sequences from which ORFs were predicted within the pipeline (i.e. this thisn’t possible with amino acid sequences). The goal of this tutorial is to show you how to use treesapp abundance to calculate TPM for metagenome-derived ORF sequences. 6.2 Workflow description The workflow employed by TreeSAPP is common to many bioinformatics pipelines: Collect nucleotide sequences for the classified ORFs. BWA (9) creates an index from these nucleotide sequences - this will be the reference database. Align the short reads to the reference database with BWA MEM. Calculate the relative abundance metrics. TreeSAPP uses samsum. There are potentially two common use cases for treesapp abundance. Through treesapp assign where a single sample’s read data are mapped to its corresponding assembly (i.e. contigs or scaffolds) and the relative abundances of these sequences are obtained. A combined assembly was generated from multiple samples, classified with treesapp assign, then the reads of each sample were mapped individually to generate sample-specific relative abundance values with treesapp abundance. 6.3 Usage There are two required arguments for treesapp abundance: treesapp_output: Path to the output directory from treesapp assign. reads: Path to a FASTQ file containing single-end reads, or foward mates or interleaved reads from a paired-end sequencing library. Below are descriptions for the most important options: reverse: Path to a FASTQ file containing reverse mates from a paired-end sequencing library. report: This argument controls what treesapp abundance does with the resulting abundance values. The ‘nothing’ option is most applicable to the Python API, and is used by treesapp assign to simply return the abundance object instances. ‘update’ can be used when the abundance values in the classification table should be replaced with these newly calculated values. ‘append’ should be used when reads of new samples are being used to calculate abundance (e.g. reads from a time-course experiment). metric: Either Fragments per Kilobase per Mllion mappable reads (FPKM) or Transcripts per Million (TPM). 6.4 Outputs The sole output of treesapp abundance is an edited classification table, previously generated by treesapp assign. No new files are generated, beyond intermediate files (e.g. SAM files). The values are in the ‘Abundance’ field of final_outputs/marker_contig_map.tsv. 6.5 Tutorial steps Connect to your group’s server, then move to the directory /data/ts_tutorial. cd /data/ts_tutorial/ This tutorial requires many fastq and fasta formatted files, that are subsetted versions of the originals. They were created by searching metagenome assemblies and reads for XmoA then pulling out all sequences that matched into new files. We are going to save them in a new directory to keep ts_tutorial organized. Create a new directory called SI072_data and download the data to it. mkdir SI072_data cd SI072_data wget https://raw.githubusercontent.com/EDUCE-UBC/MICB425/main/data/SI072_abundance_files.txt wget -i SI072_abundance_files.txt We can move back out into the /data/ts_tutorial/ directory again to run the TreeSAPP commands. cd .. We will begin by classifying XmoA sequences found in the metagenome contigs. Since these are nucleotide sequences representing random stretches of DNA from the microbial community, treesapp assign will begin by predicting open reading frames (ORFs) from these. TreeSAPP will then classify the amino acid sequences for each of the predicted ORFs. Once the XmoA sequences are classified from these ORFs we can begin to generate the relative abundance values for the XmoA sequences. Assign taxonomic labels to Saanich Inlet metagenomic contigs using the updated XmoA reference package with treesapp assign. treesapp assign \\ -n 4 \\ --trim_align \\ --refpkg_dir XmoA_MAG_update/final_outputs/ \\ --fastx_input SI072_data/SI072_MetaG_contigs.fasta \\ --output SI072_MetaG_contigs_XmoA_assign/ Now we’ll need to access the processed data generated by treesapp assign in SI072_MetaG_contigs_XmoA_assign/. treesapp abundance will access the ORFs in SI072_MetaG_contigs_XmoA_assign/intermediates/orf-call/SI072_MetaG_contigs_ORFs.fna and pass these to bwa mem for sequence alignment. Due to this, the flag ‘--delete’ should not be used with treesapp assign if you want to eventually run treesapp abundance as the intermediates directory would be removed. We will begin by calculating TPM for the metagenome reads. The reads we are using to calculate these values are paired-end meaning that the there are two reads to represent each sequenced DNA fragment. These two reads, in the case of the metagenomic data, are split across two files: one for the reads sequenced in the forward direction and another for the reads sequenced in the reverse. Their extensions are ‘.1.fq.gz’ and ‘.2.fq.gz’, respectively. Therefore, we must use the parameters ‘--reads’ and ‘--reverse’ to point TreeSAPP towards these files. You’ll notice that we didn’t list out seven files for each, either; we used a wildcard character (the asterisk). For the forward reads, the shell will interpret this as all files within the SI072_data directory that begin with ‘SI072_’ and end with ‘m_pe.1.fq.gz’. You can test this expansion using the ls command. ls SI072_data/SI072_*m_pe.1.fq.gz We would like to replace the current abundance values from treesapp assign (set to 1) with the new TPM values, so we will set the ‘--report’ parameter to ‘update’. Finally, we can specify that we want TPM values with --metric tpm. Although, ‘tpm’ is the default so this isn’t necessary. Run treesapp abundance to overwrite the previous abundance values with the TPM values calculated from each of the seven SI072 datasets. treesapp abundance \\ -n 4 \\ --treesapp_output SI072_MetaG_contigs_XmoA_assign/ \\ --reads SI072_data/SI072_*m_pe.1.fq.gz \\ --reverse SI072_data/SI072_*m_pe.2.fq.gz \\ --report update \\ --metric tpm Now we’re going to generate TPM values for the seven matching metatranscriptome datasets. You will notice the format of these FASTQ files is different from the metagenomes. All of the reads for each sample are contained in a single file, and this is referred to as interleaved FASTQ format. Since there is no file for the reverse reads we can just use the ‘--reads’ parameter. Another key difference is we’re setting the ‘--report’ parameter to ‘append’. This is because we don’t want to overwrite the TPM values we just generated for the metagenomes. Instead, we want the new metatranscriptome values to be added to SI072_MetaG_contigs_XmoA_assign/final_outputs/marker_contig_map.tsv, so in the end the classification table will hold TPM values for both the metagenomes and metatranscriptomes. Use treesapp abundance to calculate TPM values from the seven metatranscriptomes. treesapp abundance \\ -n 4 \\ --treesapp_output SI072_MetaG_contigs_XmoA_assign/ \\ --reads SI072_data/SI072_*m_MetaT_QC_Filtered.fq.gz \\ --pairing pe \\ --metric tpm \\ --report append The next tutorial will cover visualizing the TreeSAPP classifications. For this we also want the functional annotations that we generated in the last tutorial. Run treesapp layer to annotate the XmoA query sequences with their respective paralog. treesapp layer \\ -o SI072_MetaG_contigs_XmoA_assign/ \\ --refpkg_dir XmoA_MAG_update/final_outputs/ \\ -c XmoA_colours/XmoA_Function_colours_style.txt That’s it! You’re now a seasoned veteran of TreeSAPP. 6.6 Use your group’s reference package to calculate abundances Continue to work with your group’s reference package in the directory /data/&lt;gene name&gt;. Visualize the appropriate outputs with iTOL. "],["analysing-the-treesapp-classifications-in-r.html", "7 Analysing the TreeSAPP classifications in R 7.1 Introduction and goals 7.2 Resources for analysis of TreeSAPP output in R 7.3 Checklist to write and run R script 7.4 Writing the R script 7.5 Load any required packages 7.6 Load metagenomic and metatranscriptomic TreeSAPP data 7.7 Subset your data to the variables and marker genes of interest 7.8 Reformat variables 7.9 Load the geochemical data 7.10 Visualize the taxonomic, functional and chemical data from Saanich Inlet 7.11 Analyzing classifications for your group’s reference package", " 7 Analysing the TreeSAPP classifications in R 7.1 Introduction and goals These instructions will help you to complete the script template treesapp_analysis.R to complete the initial analysis of your TreeSAPP classifications. The following code chunks will show you how to load, aggregate, subset and transform continuous and discrete variables in R using the tidyverse. You will also be provided with examples for plotting TreeSAPP classification data using the ggplot2 library. 7.2 Resources for analysis of TreeSAPP output in R The TreeSAPP output file extra_annotated_marker_contig_map.tsv with the metagenome and metatranscriptome abundances and gene functions you generated with TreeSAPP. If you are unable to retrieve this file, it can be downloaded from here. An R script template called treesapp_analysis.R on Canvas. Saanich_TimeSeries_Chemical_DATA.csv file containing geochemical measurements on Canvas. 7.3 Checklist to write and run R script Place treesapp_analysis.R, extra_annotated_marker_contig_map.tsv and Saanich_TimeSeries_Chemical_DATA.csv files into a single folder and create a new RStudio project in that folder on your local computer. Edit the treesapp_analysis.R script following the instructions below. 7.4 Writing the R script In the treesapp_analysis.R script you will load and subset your TreeSAPP data to the variables and marker genes of interest. You will then break the one taxonomic information column into multiple taxonomic ranks. You will also load the Saanich_TimeSeries_Chemical_DATA.csv file for geochemical measurements to learn more about the conditions at your assigned depth. Finally, you will visualize the taxonomic, functional and chemical data using the ggplot2 library. To complete this, replace all instances of test between angle brackets, like &lt;SOME TEXT&gt;, with the code in each section. 7.5 Load any required packages library(ggplot2) library(dplyr) library(tidyr) 7.6 Load metagenomic and metatranscriptomic TreeSAPP data ts_dat &lt;- read.table(file=&quot;extra_annotated_marker_contig_map.tsv&quot;, header=TRUE, sep=&quot;\\t&quot;) 7.6.1 Classification table Let’s look at TreeSAPP’s classification table for these FunGene XmoA sequences. In RStudio, you are able to click on a variable name under the “Environment” tab in the top-right panel. Optionally, you can use the View function in the R-console to view an object. For example, you could run View(ts_dat). A description of each of the fields can be found under the treesapp assign documentation page. 7.7 Subset your data to the variables and marker genes of interest Determine which variables and marker genes you will need and subset your data to them. The only “Marker” in these data is XmoA, so we will filter to XmoA. ts_df &lt;- ts_dat %&gt;% filter(Marker == &quot;XmoA&quot;) When working with real data you may be analyzing multiple reference package’s worth of data. If you want to subset those data to a couple of reference packages you will find the ‘%in%’ operator handy. In the following example we are keeping data where the Marker variable is equal to any of “XmoA”, “PmoA” or “AmoA”. In reality, they will only match “XmoA”. ts_df &lt;- ts_df %&gt;% filter(Marker %in% c(&quot;XmoA&quot;, &quot;PmoA&quot;, &quot;AmoA&quot;)) 7.8 Reformat variables 7.8.1 Processing taxonomic information Your taxonomic information contains information from the highest to lowest available rank. Look at a few rows containing taxonomic information and determine the separator between each rank. We can use a function in the tidyverse called separate that allows you split a character object at each of these separators. As a result, your initial single taxonomic variable will be split into multiple new variables, one for each rank. Use the R object taxa_ranks to assign the names for those new variables. taxa_ranks &lt;- c(&quot;Root&quot;, &quot;Domain&quot;, &quot;Phylum&quot;, &quot;Class&quot;, &quot;Order&quot;, &quot;Family&quot;, &quot;Genus&quot;, &quot;Species&quot;) ts_df &lt;- ts_df %&gt;% separate(col = Taxonomy, into = taxa_ranks, sep = &quot;; &quot;, fill = &quot;right&quot;, remove = T) 7.8.2 Distinguishing metagenomes from metatranscriptomes ts_df &lt;- ts_df %&gt;% mutate(Sample = gsub(&quot;_pe&quot;, &quot;_MetaG&quot;, Sample)) %&gt;% separate(col = Sample, into = c(&quot;Cruise&quot;, &quot;Depth&quot;, &quot;SeqType&quot;), extra = &quot;drop&quot;) 7.8.3 Processing depth data Modify the data frame to split the sample name into “Cruise” and “Depth” variables. Then, remove the ‘m’ character from the “Depth” variable to create a numeric variable called “Depth.m”. ts_df &lt;- ts_df %&gt;% mutate(Depth.m = as.numeric(gsub(&#39;m&#39;, &#39;&#39;, Depth))) %&gt;% mutate(Cruise = as.numeric(gsub(&#39;SI0&#39;, &#39;&#39;, Cruise))) 7.9 Load the geochemical data Geochemical data for the Saanich Inlet time series is in another file called Saanich_TimeSeries_Chemical_DATA.csv. We will first load it into its own data frame called geochem_df, and subset it to just the samples we are interested in. geochem_df &lt;- read.table(&quot;Saanich_TimeSeries_Chemical_DATA.csv&quot;, header=TRUE, sep=&#39;,&#39;) %&gt;% filter(Cruise == 72) %&gt;% select(Cruise, Depth, CTD_O2, NO3, Mean_NH4, Mean_NO2, Mean_H2S, Mean_CH4) %&gt;% mutate(Mean_CH4 = Mean_CH4*1E-3) %&gt;% mutate(across(.fns=as.numeric)) We are going to use the function left_join from the dplyr library to merge the geochemical data for cruise 72 with the TreeSAPP classifications for XmoA by Sample. The combined data will be saved to a new data frame called ts_geo_df. ts_geo_df &lt;- left_join(ts_df, geochem_df, by=c(&quot;Cruise&quot;, &quot;Depth.m&quot; = &quot;Depth&quot;)) 7.10 Visualize the taxonomic, functional and chemical data from Saanich Inlet 7.10.1 Analyze TreeSAPP’s taxonomic classifications We’re going to begin with making a line plot to show the distribution of abundances of taxonomic orders at different depths. The only taxa that will be shown are those with an XmoA gene and these are not the only organisms in Saanich Inlet! We will create a new variable called Sum that sums all the Abundance (TPM values) for each taxonomic order at each depth. Without the group_by() function, it would return a single value but since we’re grouping by Depth and Order, sum yields a value for each taxon at each depth. ts_geo_df %&gt;% filter(SeqType == &quot;MetaG&quot;) %&gt;% group_by(Depth.m, Order) %&gt;% summarise(Sum = sum(Abundance)) %&gt;% ungroup() %&gt;% ggplot(aes(x=Depth.m, y=Sum, colour=Order)) + geom_line() + coord_flip() + scale_x_reverse() + labs(x=&quot;Depth (m)&quot;, y=&quot;Relative abundance (TPM)&quot;) ggsave(&quot;taxonomic_order_lineplot.png&quot;) The above plot gives us an idea of the absolute TPM values, but what is each taxon’s share of the total abundance at each depth? To answer this we will create a stacked barplot to show the relative change in proportions at different depths. Instead of creating a variable to hold each taxon’s total TPM we will create a new variable to store the proportion of TPM called Proportion. This could easily be changed to a percentage by multiplying it by 100. In the ts_geo_df dataframe there are two variables storing the sample depth: one is a numeric type and the other is a character type. We will be plotting the character type depth (Depth) on the x-axis but by default R’s alphabetical ordering makes ‘100m’ precede ‘10m’. The reorder function is used here to ensure that the depth is sorted numerically by ordering Depth (character type) by Depth.m (numeric type). Additionally, we are faceting this plot by the sequence type: ‘MetaG’ (metagenome) and ‘MetaT’ (metatranscriptome). ts_geo_df %&gt;% group_by(Depth, Depth.m, SeqType) %&gt;% mutate(Proportion = Abundance/sum(Abundance)) %&gt;% group_by(Depth, Depth.m, Order, SeqType) %&gt;% summarise(sum = sum(Proportion)) %&gt;% ungroup() %&gt;% mutate(Depth = reorder(Depth, Depth.m)) %&gt;% ggplot(aes(x=Depth, y=sum, fill=Order)) + geom_bar(stat = &quot;identity&quot;) + facet_wrap(~SeqType) + labs(x=&quot;Depth&quot;, y=&quot;Relative abundance&quot;) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) ggsave(&quot;taxonomic_order_barplot.png&quot;) 7.10.2 Analyze the functional data In the following figure we are instead going to visualize the abundance of each classified XmoA’s Function across the water column. We are going to use a bubble-plot for this figure where the bubbles at each depth-order intersection are scaled by the TPM value (Abundance). We are colouring the bubbles according to their assigned Function. We are again faceting this plot by the sequence type. ts_geo_df %&gt;% group_by(Depth, Depth.m, SeqType, Order, Function) %&gt;% summarise(Sum = sum(Abundance)) %&gt;% ungroup() %&gt;% mutate(Depth = reorder(Depth, desc(Depth.m))) %&gt;% ggplot(aes(x=Depth, y=Order, colour=Function)) + geom_point(aes(size=Sum)) + facet_wrap(~SeqType) + coord_flip() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) ggsave(&quot;functional_bubbleplot.png&quot;) Can you see any discrepancies between the metagenome and metatranscriptome abundances? 7.10.3 Analyze the chemical measurements The following plot is for visualizing the chemical profiles for each depth. This is not exhaustive but does include most of the molecules we’re interested in. To generate this plot, we’ve had to perform a common data manipulation technique called pivoting. Essentially, instead of having a separate variable for each of the chemical measurements, we have combined them into two columns: one for the name of the molecule (which was previously the variable name) and another for their value. ts_geo_df %&gt;% pivot_longer(cols=c(starts_with(&quot;Mean&quot;), NO3, CTD_O2), values_to = &quot;Value.uM&quot;, names_to = &quot;Molecule&quot;) %&gt;% ggplot(aes(x=Depth.m, y=Value.uM)) + geom_point() + geom_line() + facet_wrap(~Molecule, scales = &quot;free_x&quot;) + coord_flip() + scale_x_reverse() ggsave(&quot;geochemical_lineplot.png&quot;) Notice that the x-axis scales all differ. This was enabled with scales = \"free_x\" in the function facet_wrap and was essential to observe the trends across the water column. Without it many of the values would be squished against the y-axis as their values are close to zero and the oxygen concentration gets up to ~200 micromolar. 7.10.4 Bringing them all together In this final figure we are going to combine the methane concentration data with the TPM values for the two orders, Methylococcales and Nitrosomonadales. ts_geo_df %&gt;% filter(SeqType==&quot;MetaT&quot;) %&gt;% filter(!is.na(Order)) %&gt;% mutate(Depth = reorder(Depth, Depth.m)) %&gt;% ggplot(aes(x=Depth, y=Abundance, colour=Mean_CH4)) + geom_boxplot() + geom_point() + facet_wrap(~Order) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) ggsave(&quot;taxonomic_order_boxplot.png&quot;) How does the abundance of these two groups change with methane concentration? 7.11 Analyzing classifications for your group’s reference package How does abundance of your gene vary with depth? Are trends similar for both RNA and DNA? How does microbial diversity vary with depth? Are trends similar for both RNA and DNA? You will need to make a decision at what taxonomic rank you will calculate diversity. Why might you not be able to use the lowest possible? Why should your taxonomic rank not be too high? How does the abundance of your gene relate to water column geochemistry in Saanich Inlet (use the chemical measurement data in Saanich_TimeSeries_Chemical_DATA.csv)? Determine the geochemical conditions at your given depths. Which is the best available terminal electron acceptor? "],["project-description.html", "8 Project description 8.1 Guiding research questions 8.2 Resources 8.3 Your submission 8.4 Timeline 8.5 Reports 8.6 Addendum", " 8 Project description In this project, you will work in groups to conduct gene-centric mapping of functional and phylogenetic anchors encoded in microbial genomes sourced from the Saanich Inlet water column. Saanich Inlet is a seasonally anoxic fjord on the coast of Vancouver Island British Columbia that serves as a model ecosystem for studying microbial community responses to ocean deoxygenation. Numerous studies from Saanich Inlet over the years have identified key microbial players mediating coupled biogeochemical cycling of carbon, nitrogen and sulfur extensible to expanding marine oxygen minimum zones throughout the global ocean. Here, you will use metagenomic and metatranscriptomic data sets generated from Cruise 72 spanning 7 depths in Saanich Inlet. In addition to fastq reads, the metagenomic data sets include assembled contigs, metagenome assembled genomes (MAGs) and single-cell amplified genomes (SAGs) spanning the genomic information hierarchy. The Cruise 72 metagenomic and metatranscriptomic data sets can be evaluated in relation to geochemical parameter information to better resolve both the metabolic potential and gene expression patterns of microbial communities inhabiting the Saanich Inlet water column. Each capstone project group will have the opportunity to use TreeSAPP and iToL to chart the abundance, expression and taxonomic diversity of functional and phylogenetic anchor genes represented in the current reference package collection. Groups can augment this collection with new reference packages produced during the TreeSAPP tutorial or at any time during the project phase depending on their research interests. Reference packages can also be updated using taxonomic information associated with the MAGs and SAGs described above. The underlying conceptual framework for this project is described in the three lectures associated with course Module 2 along with examples of data visualization approaches useful in developing a coherent scientific narrative. For a given gene encoding a biochemical transformation consider the extent to which this functionality is distributed within the community and how it is represented at different levels of biological information flow e.g. DNA versus RNA. 8.1 Guiding research questions Several options are provided to help you develop your capstone project, although each group is free to come up with an original plan of action. Please consult with the teaching team if you have questions. Select your reference package(s) for analysis based on one of the following options: Choose one or more pathways of a geochemical cycle e.g. nitrogen with reference packages already available for TreeSAPP (see table of available TreeSAPP reference packages). For example, you could select NapA, NirK, NirS, NorB, NorC and NosZ to investigate denitrification in the Saanich Inlet water column. Create new reference packages to expand the TreeSAPP collection and analyze the results. You could select a pthway within a biogeocehmical cycle which does NOT have reference packages available covering the complete pathway e.g. sulfur cycle including sulfur oxidation and DMSP conversion, or a completely new pathway with no reference packages avaialble. Select all reference packages in the collection including those developed by the class during the treesapp create tutorial and map the results. Focus on evaluating the purity of each reference package and update as needed to reflect diversity of genes endemic to the Saanich Inlet water column. Perform a preliminary analysis using the Saanich Inlet data for all depths. Update reference packages as needed based on preliminary analysis. Look for patterns in gene abundance, expression and diversity as a function of water column geochemical parameter information. 8.1.1 Questions for project with a focus on biogeochemical cycles (repeated in report structure below) How does gene and transcript abundance vary across depths for each reference package for a given biogeochemical cycle? How does microbial diversity differ among and between steps within a pathway e.g. denitrification? Are these trends similar for both genes and transcripts at different depths? What is the taxonomic breakdown of genes and transcripts within a given biogeochemcial cycle? Can you discern evidence for horizontal gene transfer of one or more functional anchor genes? Can you identify evidence for distributed metabolism within one or more pathways? Are these trends similar for both genes and transcripts at different depths? How do answers to questions 2 and 3 vary depending on the taxonomic rank used in the analysis? How does the abundance, expression and taxonomy of identified genes relate to water column geochemical parameter information (use the geochemical data in Saanich_Data.csv from our previous data science sessions)? 8.1.2 Questions for project with a focus on using all reference packages In addition to the questions provided above for biogeochemical cycles consider quality control metrics in your analysis. How does the purity of each reference package impact your results? How much information is discarded due to insufficient taxonomic resolution? How much information is retained after updating reference packages with MAGs or SAGs? What is the impact on diversity metrics following the use of updated reference packages? 8.2 Resources You will be provided with a script template for both the shell and R portion of your analysis (treesapp_analysis.sh and treesapp_analysis.R) that will guide you as you develop your code. As stated in the project description, you will have access to metagenomic and metatranscriptomic data sets generated from Cruise 72 spanning 7 depths in Saanich Inlet, MAGs and SAGs. 8.3 Your submission Your final submission will consist of 3 separate files: the report itself (docx or pdf), one shell script treesapp_analysis.sh, and one R script treesapp_analysis.R (both script files must be in plain text format). The report should not contain any code, but should contain versions of software tools used and a high-level description of your workflow (i.e describe what was done and NOT how). 8.4 Timeline The following provides an outline as well as some specific milestones within the project. Capstone timeline Date Description Mar 29 Introduction and begin running TreeSAPP Ideally, your analyses on the server should run over night Mar 31 Start of capstone project Group work Apr 7, 9, 12 Group work Apr 14 Course recap and discussion April 14–24 Report writing Groups are expected to meet remotely as needed over the Finals Period in order to complete the report. This report serves as a final for this course and should be treated as such. April 24 Final due date For reports and completed portfolios 8.5 Reports Reports should be formatted as per the Instructions to Authors for the Journal of Bacteriology. Each group will submit one report with the sections below. Report structure Section Description Abstract 200–250 words Note that an Importance section is not required. Introduction 500–750 words Introduce Saanich Inlet as a model ecosystem for studying microbial community responses to ocean deoxygenation e.g. seasonal cycles, relevant biogeochemistry, previous studies, etc. Overview of a geochemical cycle including its global impacts, microbial foundations and involved genes. Methods 300–500 words Briefly describe the data (sampling, sequencing, processing, etc.) Briefly describe your analysis methods including TreeSAPP version and commands used iTOL version R version and packages used Statistics (if applicable) Provide one single shell script and one single R script (i.e treesapp_analysis.sh and treesapp_analysis.R) as individual files (i.e. not as part of your manuscript) containing the complete code to generate your results. Results 500–750 words Your analysis should address the guiding research questions you have developed. You must include ≥ 5 figures/panels with titles and full captions. These figures can be combined into multi-panel figures if desired. Discussion 750–1000 words Frame results within a broader discussion of Saanich Inlet (Apr 14 discussion). Propose evolutionary, environmental, etc. reasoning for distributed metabolism as seen in the geochemcial pathway. Future directions References 10 or more Formatted in the ASM style such as for the Journal of Bacteriology. If you are using a reference manager, this style can be downloaded for EndNote, Mendeley, or Zotero. Make sure to include citations for the data source papers and software tools used! 8.6 Addendum 8.6.1 Abundance The workflow introduced in the treesapp abundance tutorial was supposed to serve as the guide to generating TPM values for your capstone project. However, it has come to the attention of the teaching team that treesapp abundance fails to generate the simple_bar.txt files for viewing the distribution of TPM values across a reference package’s phylogenetic tree. Therefore, we are providing you another workflow that will generate both the classifications file (marker_contig_map.tsv) with TPM values and all simplebar.txt files for iTOL. 8.6.1.1 Generate the JPlace with all classifications With the concatenated metagenome FASTA file for SI072 (MetaG_Assemblies/SI072_All_contigs.fa; see server data locations) run treesapp assign without FASTQ reads and abundance flags to generate a single jplace file containing all reference package homologs across all the depths. 8.6.1.2 Generate TPM values for metagenomes Run treesapp assign seven times with abundance flags (--rel_abund and --metric TPM) and paths to metagenome FASTQ files to generate TPM values for each individual depth and the abundance files needed for iToL visualization. This gives you a total of 8 treesapp assign runs with associated output files for the metagenome samples. 8.6.1.3 Generate TPM values for metatranscriptomes Run treesapp assign with abundance flags once for each of the seven metatranscriptome samples, including their respective FASTQ file path in the command. This will give you another seven treesapp assign outputs for a total of 15 to complete the process for metagenome and metatranscriptome data sets. 8.6.1.4 Generate the file with all classifications and TPM values Now concatenate the marker_contig_map.tsv files from the seven individual depth runs for analysis in R. You will first need to write the header from one classification table to the combined table file (SI072_combined_marker_contig_map.tsv below), then write the classifications from all tables without the header. This is to avoid including the table’s header multiple times partway through the table, which would confuse R. We’re using grep to accomplish this by removing any lines that match a word in the header, ‘Query’. head -n 1 &lt;path to treesapp assign output directory&gt;/final_outputs/marker_contig_map.tsv &gt;SI072_combined_marker_contig_map.tsv cat &lt;path to assign outputs&gt;/*/final_outputs/marker_contig_map.tsv | grep -v Query &gt;&gt;SI072_combined_marker_contig_map.tsv 8.6.1.5 Viewing the placements and TPM bars in iTOL For iToL visualization use the jplace file from treesapp assign with the concatenated metagenome FASTA to visualize the phylogenetic tree with all placements across depths, and use the _labels.txt file from the concatenated run to name the leaves. To add the TPM abundance layers for each depth access the simple_bar.txt files from each individual depth run and drag and drop these files into the iToL GUI. "],["assessment.html", "9 Assessment 9.1 Peer evaluation (10%) 9.2 Report (20%) 9.3 UJEMI submission", " 9 Assessment Reports will account for 30% of the course marks distributed as follows. 9.1 Peer evaluation (10%) Total: 40 pts Peer assessment will occur through CATME wherein everyone will assess themselves and their group members. Marks will be scaled to your evaluation score with 90%+ (or 0.9+ out of 1 within CATME) counting as full marks. Individuals who do not adequately contribute to their group will forfeit the 5% contributions mark and may be asked to complete the project on their own. Peer assessment includes: Contributing to the team’s work Interacting with teammates Expecting quality Having related knowledge, skills, and abilities Individuals score themselves and all team members on a scale of 1 (unsatisfactory) – 3 (satisfactory) – 5 (excellent) in these categories. Scores are then averaged and scaled within team such that 1 corresponds to all team members contributing equally to all categories of assessment: 1+ = Mostly 5s 0.95 = Mostly 4s 0.8 = Mostly 3s 0.65 = Mostly 2s 0.5 = Mostly 1s Marks will be scaled to your CATME score based on the following: 0.9 - 1+ = 100% = 40 0.8 - 0.89 = 90% = 36 0.7 - 0.79 = 80% = 32 0.6 - 0.69 = 70% = 28 &lt;0.6 = Assessed on a case-by-case basis Unwarranted blanketed low scoring of your team or high scoring of yourself will result in the removal of your scores from the average so that they do not unfairly impact you or your team members. If issues occur within your group, please do not hesitate to contact Dr. Hallam (shallam@mail.ubc.ca), or Dr. Koenig (stephan.koenig@ubc.ca) at any point. 9.2 Report (20%) Total: 80 pts Each group will submit an electronic copy of their group’s final report (due April 24). Reports will be assessed on: Completion of relevant analyses toward answering biological questions Logic and completeness of conclusions made from these analyses Writing clarity, grammar, and style Figure clarity, effectiveness, and relevance Rubric for capstone project Poor (0–1 pts) Below average (2–4 pts) Good (5–7 pts) Excellent (8–10 pts) Abstract Not provided Summarizes only part of the report or contains numerous inaccuracies Summarizes most of the report including relevant results; Some inaccuracies or missing pieces Accurately summarizes the report including background, relevant results, and conclusions; Few to no inaccuracies Introduction Background information not provided or provided but not relevant to the research question(s); Hypotheses / questions are not stated nor supported by relevant sources Background is relevant but not sufficient to frame the research question(s); Hypotheses / questions are unclear and/or unsupported Background is relevant but does not fully frame the research question(s); Hypotheses / questions are unclear or unsupported Background is relevant and fully frames the research question(s); Hypotheses / questions are clearly stated and supported by scientific sources Methods Incomplete and missing numerous methods used; Unclear or confusing Missing several methods used; Numerous errors or unclear statements Missing one or more methods used; Results could not be replicated due to issues with clarity or accuracy Sufficient to allow replication of the results including sampling, sequencing, processing, and analysis; Succinct and not overly wordy Code (R and TreeSAPP) Code missing significant portions or is not provided Code is incomplete or erroneous such that results cannot be replicated; No explanation of code is given Code replicates results but is verbose or inefficient; Minimal commenting is provided Code replicates results and is efficient; Detailed explanation of code is provided in comments using # notation Results Most of the research questions are not addressed or the results are consistently incomplete or irrelevant Several research questions are not addressed; Numerous results are incomplete, erroneous, or irrelevant 1 or more research questions are not fully addressed; Some results are incomplete or do not to pertain to the questions All research questions are investigated with relevant analyses and figures; Results are clearly stated and not incorrectly or over-interpreted Figures &amp; captions 2 or fewer figures are given; Captions are incomplete or missing 3+ relevant figures are provided but lack proper formatting or completeness; Captions lack numerous details or descriptions 4+ relevant figures are provided with mostly proper formatting; Captions lack some details or descriptions 5+ relevant figures are provided with proper formatting; Captions are included for all figures and contain a title as well as description of axes, other aesthetics, and overall data trends Discussion Synthesis of results is missing or does not pertain to the data; Statements are not supported by the data Conclusions are incomplete or not relevant to the data; Multiple research questions are not addressed or results are incorrectly interpreted Conclusions restate results but without summarization or synthesis across depths; 1 or more questions are not addressed; Some results are incorrectly interpreted Results are summarized within the context of the original questions and more broadly across depths; Results are correctly interpreted and discussed with scientific language; Conclusions are supported by the data and 1 or more future directions are proposed Writing, grammar, &amp; format Grammatical errors, spelling mistakes, and/or language cause significant issues in understanding of the content throughout Numerous grammatical, spelling, or language errors that negatively impact understanding; Some language is overly verbose or informal; One or more sections significantly differ from the recommended length Some grammatical, spelling, or language errors that negatively impact understanding occur; Some language is overly verbose or informal; One section may significantly differ from the recommended length Minimal to no errors; Formal scientific language used throughout; Text flows and is easy to read; Sections adhere to word limits; Report provided in J Bacteriology format 9.3 UJEMI submission Outstanding reports will be invited to submit to The Undergraduate Journal of Experimental Microbiology and Immunology (UJEMI). More information on this will be provided near the end of the Finals Period. "],["running-treesapp-on-a-server.html", "10 Running TreeSAPP on a server 10.1 Resources for TreeSAPP analysis 10.2 Checklist to write and run shell script 10.3 Writing the shell script", " 10 Running TreeSAPP on a server These instructions will help you to complete the script template treesapp_analysis.sh to run your TreeSAPP analysis of the Saanich Inlet data of your assigned depth on the server and copy the output files to your local machine. To adjust the code examples below and in the script template, replace any angle brackets, e.g. &lt;SOME TEXT&gt;, with the missing code. 10.1 Resources for TreeSAPP analysis A shell script template called treesapp_analysis.sh on Canvas. Access to a server and &lt;server address&gt;. The Saanich Inlet data located in /mnt/datasets 10.2 Checklist to write and run shell script Edit the treesapp_analysis.sh script following the instructions below. Using the terminal on your computer, copy the script to your group’s server using:scp &lt;path to file on your computer&gt; &lt;user&gt;@&lt;server address&gt;:&lt;destination&gt; Make the script executable on the server (otherwise you won’t be able to run it). In the CLI and while in the directory containing your script, run the following command:chmod u+x treesapp_analysis.sh Still in the CLI, start a new session with screen -S &lt;session name&gt;. In the new session, start the script with ./treesapp_analysis.sh. After the script has run (will take at most 8 hours), locate the final_output/marker_contig_map.tsv files in the TreeSAPP output directories and copy each one to your local computer using scp. After these steps, you will continue with the analysis of your results in R on your local computer using R and the provided treesapp_analysis.R script template. 10.3 Writing the shell script In the treesapp_analysis.sh script, we will define some variables to make our code more readable when running commands, give some feedback to the user as the script runs, and finally run the TreeSAPP workflow. Edit the script either on your local computer or after you have copied it to the server using the text editor of your choice (e.g. RStudio on your local machine or nano on the server). 10.3.1 Defining the shell The script template starts with: #! bin/bash and defines the shell used to interpret this script and where the shell is located (i.e. the bash shell in the /bin directory). You do not need to modify anything about that step. 10.3.2 Setting a variable for your depth Let’s define our first variable with the name “depth”. Replace &lt;your depth&gt; with the depth your group has been assigned to (e.g. 100). depth=&quot;&lt;your depth&gt;&quot; 10.3.3 Providing user feedback It is good practice to provide feedback to the user while a script is running by printing messages to the terminal. Let’s print a welcome message to the terminal using the echo command to informing the user what the script is going to do. This is a great opportunity to call the depth variable that we have just defined. Hint: Remember, to call a variable, you have to prepend its name with a $, e.g. if the variable’s name is some_variable then you call it with $some_variable. echo &quot;TreeSAPP analysis of Saanich Inlet Data at Depth &lt;call depth variable&gt; m&quot; 10.3.4 Defining variable for input directory Define a variable for path to the input data directory. Let’s call the variable input_dir. &lt;variable_name&gt;=&quot;&lt;path to data directory&gt;&quot; 10.3.5 Creating output directory Define a variable for the TreeSAPP output directory and choose a name for it yourself. The directory should be located in your home directory (which is also shared between your host and container). To refer to your home directory, use the environmental variable HOME which is automatically defined by the shell (i.e. you do not need to first define it yourself). Finally, create the output directory. &lt;set output directory variable&gt; &lt;create the ouput directory&gt; 10.3.6 Reporting variables to user Let’s provide the user some feedback where TreeSAPP is going to save its output and what bind paths have been set. &lt;print command&gt; &quot;&lt;Some text explaining what variables have been set&gt;&quot; 10.3.7 Listing TreeSAPP version Let’s print the information about the configuration of TreeSAPP. treesapp info Hint: When we have very long commands in a script, we can introduce line breaks using \\ which are best used right after a space in the command (see example above after the word “following”). 10.3.8 Executing TreeSAPP analysis In the terminal (i.e. not as part of this script), check the documentation for treesapp assign, the command you will use for the automated reconstruction of a nutrient cycle (visit its wikipage to learn more). treesapp assign -h Looking at the TreeSAPP documentation, determine the flags you need in addition to the ones already included below. Time to run our analysis! You will have to identify the input file(s) that you need to process. You will run the analysis once for metagenomic (two files, forward reads are in the file that contains .1 in its name, and reverse reads in file the with .2) and once for metatranscriptomic reads (a single file that contains both forward and reverse reads) and align them to the assembled contigs. All reads are pair-end. You will need to provide the following settings using flags: Which assembly file to use. To use 8 CPUs for the analysis. To do the analysis for all marker genes provided in TreeSAPP. To output a verbose runtime log. Where to save the results. To calculate the rpkm values for detected sequences. Which reads to use and what type they are (i.e. pair-end or single-end). To delete any intermediate files generated by the analysis. To use position masking of multiple sequence alignment. Hints: Will you ouput the data for metagenomic and metatranscriptomic analysis to the same folder? Does the folder already exist? If you want the default value of a flag, then you do not need to provide it. Where is the input data located in the singularity container? Metatrascriptomic reads are NOT rRNA. In scripts you often refer to variables while combined with additional text. Let’s say you have defined the variable file_name=\"some_file\" to refer to the file some_file. Now you want to save a modified version of the file as some_file_modified. If you would write $file_name_modified, then the shell does not know that you just want to call a variable called $file_name and instead will assume you are calling a variable called $file_name_modified and will return an empty string. To indicate the beginning and end of a variable name, use curly braces. In the above example, you would use ${file_name}_modified. Optional bonus challenge: Earlier we defined the depth variable. Could you use it in some way when you define which assembly and reads you are using in the analysis? # Metagenomic analysis treesapp assign \\ -i &lt;input data dir&gt;&lt;file path to your assembly&gt; \\ -m &lt;choose the correct option&gt; \\ &lt;number of CPU threads, set to 8&gt; &lt;your output directory&gt; \\ &lt;your remaining settings&gt; # Metatranscriptomic analysis &lt;you are on your own now :)&gt; "],["the-saanich-inlet-data-set.html", "A The Saanich Inlet data set A.1 Description A.2 Data on the server A.3 Description of input data A.4 Methods A.5 Installing and running GTDB-Tk", " A The Saanich Inlet data set A.1 Description We will work with real-world data collected as part of an ongoing oceanographic time series program in Saanich Inlet, a seasonally anoxic fjord on the East coast of Vancouver Island, British Columbia: FIGURE A.1: The Saanich Inlet Figure A.1 shows a map of Saanich Inlet indicating conventional sample collection stations (S1-S9). The data used in this tutorial (sourced from S3, Cruise 72) include various geochemical measurements and the genomic and transcriptomic data of microbial samples at depths 10, 100, 120, 135, 150, 165 and 200 m. For more details about these data, see (10), and for more detailed information on the environmental context and time series data, see (11). A.2 Data on the server The Saanich data is located on the MICB425 server at /mnt/datasets/saanich/. /mnt/datasets/saanich/ ├── [ 0] directory_structure.txt ├── [492M] MAGs │   └── [492M] Concatenated │   └── [492M] All_SI072_Metawrap_MAGs.fa ├── [3.5G] MetaG_Assemblies │   ├── [630M] SI072_100m_contig.fa │   ├── [525M] SI072_10m_contig.fa │   ├── [571M] SI072_120m_contig.fa │   ├── [505M] SI072_135m_contig.fa │   ├── [396M] SI072_150m_contig.fa │   ├── [748M] SI072_165m_contig.fa │   └── [219M] SI072_200m_contig.fa │   └── [3.5G] SI072_All_contigs.fa ├── [ 64G] MetaG_Trim_QC_Reads │   ├── [4.7G] SI072_100m_pe.1.fq.gz │   ├── [4.7G] SI072_100m_pe.2.fq.gz │   ├── [4.2G] SI072_10m_pe.1.fq.gz │   ├── [4.2G] SI072_10m_pe.2.fq.gz │   ├── [4.2G] SI072_120m_pe.1.fq.gz │   ├── [4.2G] SI072_120m_pe.2.fq.gz │   ├── [4.4G] SI072_135m_pe.1.fq.gz │   ├── [4.4G] SI072_135m_pe.2.fq.gz │   ├── [4.8G] SI072_150m_pe.1.fq.gz │   ├── [4.7G] SI072_150m_pe.2.fq.gz │   ├── [6.5G] SI072_165m_pe.1.fq.gz │   ├── [6.4G] SI072_165m_pe.2.fq.gz │   ├── [3.3G] SI072_200m_pe.1.fq.gz │   └── [3.3G] SI072_200m_pe.2.fq.gz ├── [ 54G] MetaT_Raw_Reads │   ├── [8.9G] SI072_100m_MetaT_QC_Filtered.fastq.gz │   ├── [6.4G] SI072_10m_MetaT_QC_Filtered.fastq.gz │   ├── [6.8G] SI072_120m_MetaT_QC_Filtered.fastq.gz │   ├── [7.2G] SI072_135m_MetaT_QC_Filtered.fastq.gz │   ├── [10.0G] SI072_150m_MetaT_QC_Filtered.fastq.gz │   ├── [8.7G] SI072_165m_MetaT_QC_Filtered.fastq.gz │   └── [6.0G] SI072_200m_MetaT_QC_Filtered.fastq.gz ├── [181M] SAGs │   └── [181M] Concatenated_Med_Plus │   └── [181M] Saanich_Med_Plus_SAGs.fasta └── [ 42K] seq2lineage_Tables ├── [ 17K] Med_Plus_SAGs_GTDB_Taxonomies.tsv └── [ 25K] SI072_MAGs_All_GTDB_taxonomies.tsv 122G used in 8 directories, 33 files Additionally, if you would like to run GTDB-TK, the path to the GTDB refrence directory is located at /mnt/datasets/GTDB-Tk/release95/ A.3 Description of input data List of directories and their contents MAGs Within the Concatonated subdirectory, there is a single All_SI072_Metawrap_MAGs.fa fasta file which you will use with both treesapp assign and treesapp update. After the MAGs were generated with the MetaWrap pipeline (12) (see Methods), sample IDs were added to the contig headers of each MAG produced from each SI072 sample depth. The individual MAGs were then concatenated into this file. MetaG_Assemblies This directory contains seven assembled metagenomic contigs for each SI072 sample depth, and one file where each of these has been concatonated into a single file. These files will be used for the treesapp assign and abundance tutorials. These files were generated by assembling the trimmed and quality controlled reads that were generated by the Illumina HiSeq platform (see Methods). MetaG_Trim_QC_Reads This directory contains fourteen fastq files which contain the paired-end forward and reverse metagenomic reads for each SI072 sample depth. These trimmed and QC’d fastqs were generated by processing the raw reads through the Megahit workflow described below. You will use these files for treesapp abundance to get the metagenomic abundance of your assigned genes. MetaT_Raw_Reads This directory contains seven filtered and QC’d metatranscriptome fastq files for each SI072 Sample depth. These files are paired end and interleaved. These files we provided by the the JGI and generated based on the methodology below. You will use these files in treesapp abundance to calculate the metatransciptomic abundances of each gene of interest. SAGs Within the Concatenated_Med_Plus subdirectory, there is a single Saanich_Med_Plus_SAGs.fasta file which you will use with both treesapp assign and treesapp update. After the MAGs were generated with the SAG Assembly and Decontamination Workflow (13–16) (see Methods), sample IDs were added to the contig headers of each MAG produced from each SI072 sample depth. The individual MAGs were then concatenated into this file. seq2lineage_Tables This directory contains two files that will be used for treesapp update. One file contains the lineage information from the MAGs, and the other contains information for the SAGs. These tables were generated by taking each separate MAG and SAG respectively and passing them through the Genome Taxonomic Database Toolkit v1.4.0 classify workflow (7) (see Methods). Then, the first two columns of the archaeal and bacterial summary files were taken and combined into each of these files. A.4 Methods A.4.1 Metagenomes and metatransriptopmes A.4.1.1 Sample Collection Water was collected at 10, 100, 120, 135, 150, 165, and 200m at Saanich Inlet on August 1st, 2012 and filtered through a 0.22 µm Sterivex filter to collect biomass. Total genomic DNA and RNA were extracted from these filters. RNA was reversed transcribed into cDNA and both genomic DNA and cDNA were used in the construction of shotgun Illumina libraries. Sequencing data were generated on the Illumina HiSeq platform with 2x150bp technology. For more in-depth sampling and sequencing methods, please see (17). A.4.1.2 Quality filtering of reads The resulting reads were processed, quality controlled and filtered with Trimmomatic (v.0.35, documentation) (13). Trimmomatic command is as follows, where SI072_XXX represents the same command being applied to each of the seven depths. trimmomatic -threads 8 -phred33 \\ Path_to/SI072_XXXm/Raw/forward_dir/SI072_XXXm_R1.fastq \\ Path_To/SI072_200m/Raw/reverse_dir/SI072_XXXm_R2.fastq \\ Path_To/SI072_200m//trim/SI072_XXXm_pe.1.fq \\ Path_To/SI072_200m//trim/SI072_XXXm_pe.2.fq \\ ILLUMINACLIP:/usr/local/share/Trimmomatic-0.35/adapters/TruSeq3-PE.fa:2:3:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36 The resulting trimmed fastq files were also deposited into the MICB425 server in /mnt/datasets/saanich/MetaG_Trim_QC_Reads A.4.1.3 Contig Assembly MEGAHIT (v.1.1.3, documentation) (18) was used to assemble the filtered metagenomic reads into contigs. megahit -1 Path_To/SI072_200m//trim/SI072_XXXm_pe.1.fq -2 Path_To/SI072_200m//trim/SI072_XXXm_pe.2.fq -m 0.5 -t 12 -o megahit_result --k-min 27 --k-step 10 --min-contig-len 500 The resulting assemblies can be found in /mnt/datasets/saanich/MetaG_Assemblies. A.4.1.4 Binning and MAG Generation MetaWRAP (v1.2.4, documentation) (12) was used to generate the MAGs from the metagenome assemblies and filtered reads for this project. MetaWRAP leverages multiple binning software (we chose to use MetaBAT2 v2.12.1 (19) and MaxBin v2.2.7 (20), (21)) to create a non-redundant set of MAGs that are better quality than those from any single software. The quality of the resulting bins – assessed by their completeness, contamination, and strain-heterogeneity – was calculated with MetaWRAP’s implementation of CheckM (v1.0.12) (15). The command used to invoke MetaWRAP is as follows: metawrap binning -a SI072_Assembly.fa -o output_directory -t 16 -m 64 -l 1500 --metabat2 --maxbin2 --universal Path_To/SI072_200m//trimSI072_XXXm_pe.1.fastq Path_To/SI072_200m//trimSI072_XXXm_pe.2.fastq A.4.1.5 Taxonomic Assignment of MAGs The resulting MAGs were then passed through GTDB-TK v1.4.0 classify workflow with the reference data version r95 documentation (7). gtdbtk classify_wf --genome_dir Path_To_SI072/MAGs/ -x .fa --out_dir Path_To_SI072/MAG_GTDB_Outputs/ --cpus 8 --pplacer_cpus 8 After updating the headers for resulting 219 bins with the sample IDs, the bins were concatenated and deposited into: /mnt/datasets/saanich/MAGs/Concatenated/ A.4.2 Single-Cell Amplified Genomes A.4.2.1 Sample Collection Water was collected at across the water column at Saanich Inlet on August 9th, 2011. 900 µL of seawater was aliquoted into 100 µL of glycerol-TE buffer, then stored at -80 degrees Celsius. Samples from 100m, 150m, and 185m were selected for sorting and sequencing. The selected samples were thawed and had their microbial cells sorted at the Bigelow Laboratory for Ocean Sciences’ Single Cell Genomics Center (scgc.bigelow.org). A.4.2.2 Florescence Activated Cell Sorting Samples were passed through a sterile 40 𝜇m size mesh before microorganisms were sorted by a non-targeted isolation procedure. For non-target isolation, the microbial particles were labeled with a 5 𝜇M final concentration of the DNA stain SYTO-9 (Thermo Fisher Scientific). Microbial cells were individually sorted using a MoFloTM (Beckman Coulter) or an InFluxTM (BD Biosciences) flow cytometer system equipped with a 488 nm laser for excitation and a 70 μm nozzle orifice30. The gates for the untargeted isolation of microbial cells stained with SYTO-9 were defined based on the green fluorescence of particles as a proxy for nucleic acid content, and side scattered light as a proxy for particle size. All microbial single cells were sorted into 384-well plates containing 600 nL of 1X TE buffer per well and then stored at -80 degrees Celsius. The microbial single-cells sorted into TE buffer were lysed as described previously by adding cold KOH.The microbial nucleic acids were then amplified in each individual wells through Multiple Displacement Amplification (MDA) (22), (23). A.4.2.3 Amplicon Taxonomic Screening SAGs generated through the MDA methodology were taxonomically characterized by sequencing a determined phylogenetic marker using an amplification based approach. SAGs were screened for their small subunit ribosomal rRNA gene (SSU rRNA) using primers for bacterial (27-F: 5’- AGAGTTTGATCMTGGCTCAG -3’37, 907-R: 5’- CCGTCAATTCMTTTRAGTTT -3’38 and archaeal sequences (Arc_344F: 5’- ACGGGGYGCAGCAGGCGCGA -3’39, Arch_915R: 5’- GTGCTCCCCCGCCAATTCCT -3’40). The real-time PCR and sequencing procedure of the resulting amplicons was performed as previously described (24), (25). The partial SSU rRNA gene sequences were then queried against the SILVA database v138.1 (26) with blastn, from BLAST+ v2.9.0 (27). blastn -query -db -outfmt &quot;6 qacc sacc stitle staxid pident bitscore&quot; -max_target_seqs 1 -num_threads 4 -out A.4.2.4 SAG Sequencing and Assembly MDA products for the SAGs were sequenced as described previously (24), (25) on an Illumina HiSeq 2000. The resulting raw reads were then filtered and trimmed to remove adaptors with Trimmomatic v0.35 (13). trimmomatic -threads 8 -phred33 \\ Path_to/SI072_XXXm/Raw/forward_dir/SI072_XXXm_R1.fastq \\ Path_To/SI072_200m/Raw/reverse_dir/SI072_XXXm_R2.fastq \\ Path_To/SI072_200m//trim/SI072_XXXm_pe.1.fq \\ Path_To/SI072_200m//trim/SI072_XXXm_se.1.fq \\ Path_To/SI072_200m//trim/SI072_XXXm_pe.2.fq \\ Path_To/SI072_200m//trim/SI072_XXXm_se.2.fq \\ ILLUMINACLIP:/usr/local/share/Trimmomatic-0.35/adapters/TruSeq3-PE.fa:2:3:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36 Trimmed and quality controlled reads were the then assembled with SPAdes v3.9.0 (28) with standard parameters. spades.py \\ --sc \\ -o Path_To_assembly_dir/ \\ -1 Path_To_trim_dir/SI072_XXXm_pe.1.fq \\ -2 Path_To_trim_dir/SI072_XXXm_pe.1.fq \\ -s Path_To_trim_dir/$sample\\_unpaired.fq \\ -k $k_series \\ --memory 90 \\ --threads $threads \\ --careful \\ --cov-cutoff auto A.4.2.5 SAG Assembly Quality Control and Decontamination Quality of the SAGs was assessed using CheckM (v1.0.5) (15) with the following command: checkm lineage_wf --tab_table -x .fna --threads 8 --pplacer_threads 8 SAGs found to have &gt;5% contamination were passed through ProDeGe v2.3.0 (16). The resulting decontaminated SAGs were re-assesed with CheckM and those that still exceeded 5% contamination had all of their short contigs (i.e. &lt;2000 bp) removed from the assembly. These were again re-assessed with CheckM to ensure they met our standards. For this project, of the 376 SAGs recovered, 154 SAGs that were estimated to have &gt;50% completeness and &lt;10% contamination were selected for the remainder of the analysis. A.4.2.6 Final Taxonomic Assignment of SAGs The resulting SAGs were then passed through GTDB-TK v1.4.0 classify workflow documentation (7). gtdbtk classify_wf --genome_dir Path_To_SI_SAGs/ -x .fna --out_dir Path_To_SI_SAGs/GTDB_1.4.0/ --cpus 8 --pplacer_cpus 8 After updating the headers for resulting SAGs with the sample IDs, the SAGs were concatenated and deposited into: /mnt/datasets/saanich/SAGs/Concatenated_Med_Plus/ Note: The identifier for each SAG consists of a combination of the plate ID and the well location it was sorted into. The identifiers take the form (AB-7XX_YYY). These identifiers were incorporated into the headers of the final SAG assemblies. Each plate corresponds to a specific depth as shown below: Plate ID Sample Depth (m) AB-746 100 AB-747 100 AB-750 150 AB-751 150 AB-754 185 AB-755 185 A.5 Installing and running GTDB-Tk If you would like to use additional genomes or MAGs for you capstone project, you can also classify them with GTDB-Tk. If you would like to install GTDB-TK with conda, you will first need to create a new conda environment. First, deactivate the treesapp environment: conda deactivate treesapp_cenv follow the instructions below (originally from: GTDB) To install GTDB with conda: # specific version (replace 1.4.1 with the version you wish to install, recommended) conda create -n gtdbtk-1.4.1 -c conda-forge -c bioconda gtdbtk=1.4.1 Once you have made your new GTDB environment, you will need to add a path to the latest GTDB reference data. conda activate gtdbtk-1.4.1 Next, determine the GTDB-Tk environment path which gtdbtk It should be root/miniconda3/envs/gtdbtk-1.4.1/bin/gtdbtk Next, edit the activate file echo &quot;export GTDBTK_DATA_PATH=/mnt/datasets/GTDB-Tk/release95/&quot; &gt; /root/miniconda3/envs/gtdbtk-1.4.1/etc/conda/activate.d/gtdbtk.sh You are now ready to use the classify workflow command listed above. You will need to substitute the directory name that you would like to write out to, as well as the extension of the fasta files for your genomes. It is very important you set the cpus and pplacer_cpus flags to 4 threads to make sure you do not tie up all of the server’s resources! gtdbtk classify_wf --genome_dir Path_To_Genomes/ \\ -x [Choose either .fa, .fasta, or .fna depending on the file extension] \\ --out_dir [Path_To_New_Genome_Output/here] \\ --cpus 4 \\ --pplacer_cpus 4 After running GTDB, you can deactivate the environment with: conda deactivate You can then turn the treesapp environment back and continue with your treesapp analysis. conda activate treesapp_cenv We recommend concatenating your new genomes together with cat into a single file for ease of use. For example: cat *.fasta &gt; All_Genomes.fasta "],["treesapp-reference-packages.html", "B TreeSAPP reference packages", " B TreeSAPP reference packages TABLE B.1: Available TreeSAPP reference packages Name Description Leaf nodes Pathway Cycle AA10 Auxiliary Activity family 10 699 Carbohydrate metabolism C GH101 Glycoside hydrolase family 101 113 Carbohydrate metabolism C GH102 Glycoside hydrolase family 102 727 Carbohydrate metabolism C GH103 Glycoside hydrolase family 103 1145 Carbohydrate metabolism C GH109 Glycoside hydrolase family 109 376 Carbohydrate metabolism C GH115 Glycoside hydrolase family 115 267 Carbohydrate metabolism C GH126 Glycoside hydrolase family 126 112 Carbohydrate metabolism C GH163 Glycoside hydrolase family 163 102 Carbohydrate metabolism C GH67 Glycoside hydrolase family 67 372 Carbohydrate metabolism C GH94 Glycoside hydrolase family 94 695 Carbohydrate metabolism C McrA Methyl coenzyme M reductase alpha subunit 424 Methanogenesis C McrA Methyl coenzyme M reductase alpha subunit 249 Methanogenesis C McrB Methyl coenzyme M reductase beta subunit 110 Methanogenesis C McrG Methyl coenzyme M reductase gamma subunit 123 Methanogenesis C PHAdeg Poly(hydroxyalkanoate) degradation enzymes 10 Plastics degradation C PL11 Polysaccharide lyase family 11 320 Carbohydrate metabolism C PuhA photosynthetic reaction center H subunit 47 Photosynthesis C PilA Type IV pilin N-terminus, including PilA 70 Direct interspecies electron transfer E HydA [FeFe] hydrogenase, group A, B1, B3 93 Hydrogenase H HgcA Methylmercury active enzyme, subunit A 108 NA Hg HgcB Methylmercury active enzyme, subunit B 122 NA Hg NapA Periplasmic nitrate reductase, large subunit 765 Denitrification N NifD nitrogenase molybdenum-iron protein alpha chain 926 Nitrogen fixation N NifH Nitrogenase iron protein [TIGR01287,EC:1.18.6.1] 660 Nitrogen fixation N NirK nitrite reductase (NO-forming) 325 Denitrification,Annamox N NirS nitrite reductase (NO-forming) / hydroxylamine reductase 511 Denitrification,Annamox N NorB nitric oxide reductase subunit B 460 Denitrification N NorC nitric oxide reductase subunit C 173 Denitrification N NosZ Nitrous-oxide reductase (TAT-dependent|Sec-dependent) 26 Denitrification N NxrA nitrate reductase / nitrite oxidoreductase, alpha subunit 658 Nitrification N NxrB nitrate reductase / nitrite oxidoreductase, beta subunit 648 Nitrification N XmoA Alpha subunits of copper membrane monooxygenase enzymes 37 Nitrification N PF00380a Ribosomal protein S9/S16 82 Translation NA PF00380b Ribosomal protein S9/S16 1065 Translation NA PF00410a Ribosomal protein S8 155 Translation NA PF00410b Ribosomal protein S8 1216 Translation NA PF00687a Ribosomal protein L1p/L10e family 192 Translation NA PF00687b Ribosomal protein L1p/L10e family 864 Translation NA PF00750a tRNA synthetases class I (R) 193 Translation NA PF00750b tRNA synthetases class I (R) 1317 Translation NA PF00900 Ribosomal family S4e 328 Translation NA PF01015 Ribosomal S3Ae family 101 Translation NA PF01092 Ribosomal protein S6e 169 Translation NA PF01157 Ribosomal protein L21e 74 Translation NA PF01200 Ribosomal protein S28e 129 Translation NA PF01280 Ribosomal protein L19e 281 Translation NA PF01409a tRNA synthetases class II core domain (F) 243 Translation NA PF01409b tRNA synthetases class II core domain (F) 891 Translation NA PF01655 Ribosomal protein L32 220 Translation NA PF01866 Putative diphthamide synthesis protein 229 Translation NA RpoB RNA polymerase beta subunit 697 Translation NA CysD sulfate adenylyltransferase (SAT), small subunit 93 Assimilatory sulfate reduction S CysH phosophoadenylyl-sulfate reductase [PF01507, EC:1.8.4.8|1.8.4.10] 710 Assimilatory sulfate reduction S CysI_Sir (assimilatory) sulfite reductase (NADPH) hemoprotein, beta subunit|ferredoxin dependent 1055 Assimilatory sulfate reduction S CysJ sulfite reductase [NADPH] flavoprotein, alpha-component [COG0369, EC:1.8.1.2] 474 Assimilatory sulfate reduction S CysN Sulfate adenylyltransferase (SAT), large subunit 1221 Assimilatory sulfate reduction S DsrAB Dissimilatory sulfite reductase, alpha and beta subunits 752 Dissimilatory sulfate reduction and oxidation S DsrC 341 Dissimilatory sulfate reduction and oxidation S Sat Sulfate adenylyltransferase [PF01747, EC:2.7.7.4] 254 Dissimilatory sulfate reduction and oxidation S SoxB S-sulfosulfanyl-L-cysteine sulfohydrolase [TIGR04486] 1012 SOX system S SoxY Thiosulfate oxidation carrier protein [TIGR04488,ENOG501RH4J] 364 SOX system S SoxZ Thiosulfate oxidation carrier complex protein [TIGR04490,ENOG501N097] 247 SOX system S "],["shell-cheat-sheet.html", "C Shell cheat sheet", " C Shell cheat sheet TABLE C.1: Shell cheat sheet Command Description cd Change directory .. to parent directory ~ to home directory - to last visited directory ls List files in directory -l as list ssh &lt;username&gt;@&lt;server address&gt; Make a secure connection to server pwd Print working directory less &lt;filename&gt; Look at text file Press Help for navigation Press Quit to leave scp &lt;source&gt; &lt;target&gt; Copy files between local and server Give file path on server as &lt;user&gt;@&lt;server address&gt;:&lt;file path&gt; exit Close session (either to server or to local terminal) history Get list of command history Follow with !&lt;number&gt; to execute that corresponding command again -a &lt;filename&gt; save a history of your current session to a text file to document your work man &lt;command&gt; help &lt;command&gt; &lt;command&gt; --help Unfortunately, it is impossible to predict how to get help for a &lt;command&gt;, try any one of these until one works screen Create a virtual terminal that continues to run jobs even when your connection to server terminates -S &lt;session name&gt; create a session with &lt;session name&gt; -ls list all running sessions -r &lt;session name&gt; resume a session To leave a session but keep it running, first ctrl+activate commands to screen, then detach "],["references.html", "D References", " D References "]]
