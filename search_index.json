[["index.html", "Mapping microbes and marine denitrification 2020.21 MICB425 Capstone project Overview", " Mapping microbes and marine denitrification 2020.21 MICB425 Capstone project Stephan Koenig, Kim Dill-McFarland, Ryan McLaughlin, Connor Morgan-Lang, Steven Hallam version January 28, 2021 Overview This document contains all relevant information to complete the group project: Introduction contains the background of the data collected and the methods used so far to generate the data set you are going to work with. Instructions will give you information on the focus of your report, how to write it and evaluation. Common shell commands you will use for GCP and TreeSAPP can be found here as well as a script outline. Instructions on how to complete the R analysis. "],["introduction.html", "1 Introduction 1.1 Background 1.2 Methods 1.3 Using meta-omics data 1.4 TreeSAPP", " 1 Introduction 1.1 Background Marine oxygen minimum zones (OMZs) provide useful environmental contexts in which to study coupled biogeochemical cycling through microbial metabolic networks. Because OMZs are hotspots for nitrogen loss processes, reconstructing the nitrogen cycle as a distributed metabolic process has potential to shed new insight into microbial controls on nutrient and energy fluxes in the ocean. Genes encoding key steps in the nitrogen cycle are well defined (Figure 1.1) providing a basis for functional anchor screening to determine their distribution across the Tree of Life. FIGURE 1.1: Nitrogen cycle 1.2 Methods Water was collected from various depths at Saanich Inlet and filtered through a 0.22 µm Sterivex filter to collect biomass. Total genomic DNA and RNA was extracted from these filters. RNA was reversed transcribed into cDNA and both genomic DNA and cDNA were used in the constuction of shotgun Illumina libraries. Sequencing data were generat ed on the Illumina HiSeq platform with 2x150bp technology. For more in-depth sampling and sequencing methods, please see (1). The resulting reads were processed and quality controlled at the Joint Genome Institute using the IMG/M pipeline. Metagenomes were assembled and processed using MEGAHIT v1.1.2 at UBC. 1.3 Using meta-omics data We a trying to address the following questions: Who is there? What are they doing? How do they respond to change? The genome sequence information is a guide to the metabolic potential of the community. It represents an inventory of the microbial genotypes that are present at the time of sampling. We can use this information to identify the taxonomic structure of the sample and to provide a map for the metabolic potential at the individual, population and community levels of organization. Because DNA can persist in the environment for longer periods of time than RNA or protein, we can also use the abundance of gene X or gene Y to tell us about prior metabolic activity e.g. gene abundance is a proxy for process. We can use gene abundance information in numerical models to infer metabolic flux through a given pathway because the abundance of gene X is proportional to the replication of the genome in which it resides. Genomic information is also more robust to sampling noise as we collect and process samples for downstream analysis. For information on gene-centric modelling incorporating DNA, RNA and protein information in Saanich Inlet see this paper (2). While genomic information tells us about metabolic potential, the transcriptome is a guide to action or gene expression. We can to a certain extent use this information to identify who is there but more often it is used to indicate which pathways are active at the time of sampling. If can open a window into response patterns along environmental gradients with the caveat that its short-lived nature is less robust to sampling noise. There is no guarantee that the presence of transcripts for a given gene X are converted into protein. However, because prokaryotes couple transcription to translation we typically infer a direct relationship. For information on relationships between DNA, RNA and protein in Saanich Inlet see this paper as well (3). 1.4 TreeSAPP You will be implementing a pipeline called Tree-based Sensitive and Accurate Protein Profiler (TreeSAPP) for automated reconstruction of the nitrogen cycle along defined redox gradients in Saanich Inlet using the Google Cloud Platform. TreeSAPP takes either metagenomic or metatranscriptomic reads and aligns them to previously binned sequence data with each bin representing a putative microbial taxon. TreeSAPP determines three things: A. What taxa are in our metagenomic and metatranscriptomic data represented? B. Which marker genes do these taxa contain (metagenomic data) or actually express (metatranscriptomic data)? C. At what levels are those genes represented (metagenomic data) or expressed by the taxon? Please see the TreeSAPP wiki for more information on treesapp assign, the subcommand you will use. You will be provided with a script template for both the shell and R portion of your analysis (“treesapp_analysis.sh” and “treesapp_analysis.R”) that will guide you as you develop your code. References "],["instructions.html", "2 Instructions 2.1 Timeline 2.2 Reports 2.3 Assessment 2.4 UJEMI submission", " 2 Instructions In this project, you will work in teams to explore marine microbial communities and the nitrogen cycle, particularly denitrification. You will use metagenomic and metatranscriptomic data from Cruise 72 at 7 depths in Saanich Inlet, a seasonally anoxic fjord that serves as a model ecosystem for studying microbial community responses to changing levels of oxygen. Each group has been assigned a specific depth (given in Canvas group name) and will assess microbial communities in terms of taxonomic rank, abundance, and expression along the redoxcline in Saanich Inlet. 2.1 Timeline The following provides an outline as well as some specific milestones within the project. Mar 27: Introduction and begin running TreeSAPP Ideally, your GCP analyses should run over the weekend so that you have data to work with in class on Monday. Mar 30: Introduction to statistics; Group work Apr 1 and 3: Group work Apr 6: Project synthesis Be prepared to discuss the main conclusions that you’ve reached for your assigned depth. (April 8: Course recap and discussion) April 9-24: Report writing. Groups are expected to meet remotely as needed over the Finals Period in order to complete the report. This report serves as a final for this course and should be treated as such. April 24: Final reports due with final portfolios 2.2 Reports Reports should be formatted as per the Instructions to Authors for the Journal of Bacteriology. Each group will complete one report with the following sections. 2.2.1 Abstract 200–250 words Note that an Importance section is not required. 2.2.2 Introduction 500–750 words Overview of the nitrogen cycle including its global impacts and microbial foundations. Introduce Saanich Inlet as a model ecosystem for studying microbial community responses to ocean deoxygenation e.g. seasonal cycles, relevant biogeochemistry, previous studies, etc. 2.2.3 Methods 300–500 words Briefly describe the data (sampling, sequencing, processing, etc.) Briefly describe your analysis methods including TreeSAPP version and commands used iTOL version R version and packages used Statistics (if applicable) Provide one single shell script and one single R script (i.e “treesapp_analysis.sh” and “treesapp_analysis.R”) as individual files (i.e. not as part of your manuscript) containing the complete code to generate your results. 2.2.4 Results 500–750 words Your analysis will focus on denitrification genes at your assigned depth (which is given in your Canvas group name) and the following questions: How does abundance of denitrification genes differ across the pathway? Are trends similar for both RNA and DNA? How does microbial diversity differ across the pathway? Are trends similar for both RNA and DNA? What specific taxa are responsible for denitrification? Are they the same for all steps? For DNA versus RNA? How does the abundance of denitrification genes relate to nitrogen species in Saanich (use the geochemical data in Saanich_Data.csv from our previous data science sessions)? You must include ≥ 5 figures/panels with titles and full captions. These figures can be combined into multi-panel figures if desired. 2.2.5 Discussion 750–1000 words Frame your depth’s results within a broader discussion of Saanich Inlet and the other depths (Apr 6 discussion) Propose evolutionary, environmental, etc. reasoning for distributed metabolism as seen in the denitrification pathway Future directions 2.2.6 References 10 or more formatted in the ASM style such as for the Journal of Bacteriology. If you are using a reference manager, this style can be downloaded for EndNote, Mendeley, or Zotero. Make sure to cite the data source papers! 2.3 Assessment Reports will account for 15% of the course marks distributed as follows. 2.3.1 Peer evaluation (5%) Total: 40 pts Peer assessment will occur through CATME wherein everyone will assess themselves and their group members. Marks will be scaled to your evaluation score with 90%+ (or 0.9+ out of 1 within CATME) counting as full marks. Individuals who do not adequately contribute to their group will forfeit the 5% contributions mark and may be asked to complete the project on their own. Peer assessment includes: Contributing to the team’s work Interacting with teammates Expecting quality Having related knowledge, skills, and abilities Individuals score themselves and all team members on a scale of 1 (unsatisfactory) – 3 (satisfactory) – 5 (excellent) in these categories. Scores are then averaged and scaled within team such that 1 corresponds to all team members contributing equally to all categories of assessment: 1+ = Mostly 5s 0.95 = Mostly 4s 0.8 = Mostly 3s 0.65 = Mostly 2s 0.5 = Mostly 1s Marks will be scaled to your CATME score based on the following: 0.9 - 1+ = 100% = 40 0.8 - 0.89 = 90% = 36 0.7 - 0.79 = 80% = 32 0.6 - 0.69 = 70% = 28 &lt;0.6 = Assessed on a case-by-case basis Unwarranted blanketed low scoring of your team or high scoring of yourself will result in the removal of your scores from the average so that they do not unfairly impact you or your team members. If issues occur within your group, please do not hesitate to contact Dr. Hallam (shallam@mail.ubc.ca), or Dr. Koenig (stephan.koenig@ubc.ca) at any point. 2.3.2 Report (10%) Total: 80 pts Each group will submit an electronic copy of their group’s final report (due April 24). Reports will be assessed on: Completion of relevant analyses toward answering biological questions Logic and completeness of conclusions made from these analyses Writing clarity, grammar, and style Figure clarity, effectiveness, and relevance Poor (0-1 pts) Below average (2-4 pts) Good (5-7 pts) Excellent (8-10 pts) Abstract Not provided Summarizes only part of the report or contains numerous inaccuracies Summarizes most of the report including relevant results; Some inaccuracies or missing pieces Accurately summarizes the report including background, relevant results, and conclusions; Few to no inaccuracies Introduction Background information not provided or provided but not relevant to the research question(s); Hypotheses / questions are not stated nor supported by relevant sources Background is relevant but not sufficient to frame the research question(s); Hypotheses / questions are unclear and/or unsupported Background is relevant but does not fully frame the research question(s); Hypotheses / questions are unclear or unsupported Background is relevant and fully frames the research question(s); Hypotheses / questions are clearly stated and supported by scientific sources Methods Incomplete and missing numerous methods used; Unclear or confusing Missing several methods used; Numerous errors or unclear statements Missing one or more methods used; Results could not be replicated due to issues with clarity or accuracy Sufficient to allow replication of the results including sampling, sequencing, processing, and analysis; Succinct and not overly wordy Code (R and TreeSAPP) Code missing significant portions or is not provided Code is incomplete or erroneous such that results cannot be replicated; No explanation of code is given Code replicates results but is verbose or inefficient; Minimal commenting is provided Code replicates results and is efficient; Detailed explanation of code is provided in comments using # notation Results Most of the research questions are not addressed or the results are consistently incomplete or irrelevant Several research questions are not addressed; Numerous results are incomplete, erroneous, or irrelevant 1 or more research questions are not fully addressed; Some results are incomplete or do not to pertain to the questions All research questions are investigated with relevant analyses and figures; Results are clearly stated and not incorrectly or over-interpreted Figures &amp; captions 2 or fewer figures are given; Captions are incomplete or missing 3+ relevant figures are provided but lack proper formatting or completeness; Captions lack numerous details or descriptions 4+ relevant figures are provided with mostly proper formatting; Captions lack some details or descriptions 5+ relevant figures are provided with proper formatting; Captions are included for all figures and contain a title as well as description of axes, other aesthetics, and overall data trends Discussion Synthesis of results is missing or does not pertain to the data; Statements are not supported by the data Conclusions are incomplete or not relevant to the data; Multiple research questions are not addressed or results are incorrectly interpreted Conclusions restate results but without summarization or synthesis across depths; 1 or more questions are not addressed; Some results are incorrectly interpreted Results are summarized within the context of the original questions and more broadly across depths; Results are correctly interpreted and discussed with scientific language; Conclusions are supported by the data and 1 or more future directions are proposed Writing, grammar, &amp; format Grammatical errors, spelling mistakes, and/or language cause significant issues in understanding of the content throughout Numerous grammatical, spelling, or language errors that negatively impact understanding; Some language is overly verbose or informal; One or more sections significantly differ from the recommended length Some grammatical, spelling, or language errors that negatively impact understanding occur; Some language is overly verbose or informal; One section may significantly differ from the recommended length Minimal to no errors; Formal scientific language used throughout; Text flows and is easy to read; Sections adhere to word limits; Report provided in J Bacteriology format 2.4 UJEMI submission Outstanding reports will be invited to submit to The Undergraduate Journal of Experimental Microbiology and Immunology (UJEMI). More information on this will be provided near the end of the Finals Period. "],["shell.html", "3 Running TreeSAPP on the Google Cloud Platform 3.1 Resources for TreeSAPP analysis 3.2 Checklist to write and run shell script 3.3 Writing the shell script", " 3 Running TreeSAPP on the Google Cloud Platform These instructions will help you to complete the script template treesapp_analysis.sh to run your TreeSAPP analysis of the Saanich Inlet data of your assigned depth on the Google Cloud Platform (GCP) and copy the output files to your local machine. To adjust the code examples below and in the script template, replace any angle brackets, e.g. &lt;SOME TEXT&gt;, with the missing code. 3.1 Resources for TreeSAPP analysis A shell script template called treesapp_analysis.sh on Canvas. A Google Cloud instance for your group called group-&lt;your group number&gt;. The Saanich Inlet data located in the /usr/local/data/MICB425/SI072_Data directory of your Google Cloud instance, specifically: Metagenomic (metaG, DNA) reads: /usr/local/data/MICB425/SI072_Data/MetaG_reads/ Metatranscriptomic (metaT, RNA): reads /usr/local/data/MICB425/SI072_Data/MetaT_reads/ Assemblies of both DNA and RNA /usr/local/data/MICB425/SI072_Data/MetaG_assemblies/ A Singularity container with TreeSAPP on your Google Cloud instance at /usr/local/bin/treesapp.sif. 3.2 Checklist to write and run shell script Edit the treesapp_analysis.sh script following the instructions below. Using the command line interface (CLI) on your computer, copy the script to your group’s Google Cloud instance using: gcloud compute scp &lt;path to file on your computer&gt; &lt;group instance&gt;:&lt;destination&gt; Make the script executable on the Google Cloud instance (otherwise you won’t be able to run it). In the CLI and while in the directory containing your script, run the following command: chmod u+x treesapp_analysis.sh. Still in the CLI, start a new session with screen -S &lt;session name&gt;. In the new session, start the script with ./treesapp_analysis.sh. After the script has run (will take at most 8 hours), locate the final_output/marker_contig_map.tsv files (one copy for the metagenomic and one for the metatranscriptomic analysis) in the TreeSAPP output directory and copy each one to your local computer: gcloud compute scp &lt;group instance&gt;:&lt;path to file&gt; &lt;destination on your computer&gt; After these steps, you will continue with the analysis of your results in R on your local computer using R and the provided treesapp_analysis.R script template. 3.3 Writing the shell script In the treesapp_analysis.sh script, we will define some variables to make our code more readable when running commands, give some feedback to the user as the script runs, and finally run the TreeSAPP workflow using a Singularity container. Edit the script either on your local computer or after you have copied it to the Google Cloud instance using the text editor of your choice (e.g. RStudio on your local machine or nano &lt;file name&gt; on GCP). 3.3.1 Defining the shell The script template starts with: #! bin/bash and defines the shell used to interpret this script and where the shell is located (i.e. the bash shell in the /bin directory). You do not need to modify anything about that step. 3.3.2 Setting a variable for your depth Let’s define our first variable with the name “depth”. Replace &lt;your depth&gt; with the depth your group has been assigned to (e.g. 100). depth=&quot;&lt;your depth&gt;&quot; 3.3.3 Providing user feedback It is good practice to provide feedback to the user while a script is running by printing messages to the terminal. Let’s print a welcome message to the terminal using the echo command to informing the user what the script is going to do. This is a great opportunity to call the depth variable that we have just defined. Hint: Remember, to call a variable, you have to prepend its name with a $, e.g. if the variable’s name is some_variable then you call it with $some_variable. echo &quot;TreeSAPP analysis of Saanich Inlet Data at Depth &lt;call depth variable&gt; m&quot; 3.3.4 Defining variable for input directory Define a variable for path to the input data directory. Let’s call the variable input_dir. &lt;variable_name&gt;=&quot;&lt;path to data directory&gt;&quot; 3.3.5 Sharing the host data folder with the Singularity container The data we want to analyze with TreeSAPP is located on the host system (the Google Cloud instance), but TreeSAPP itself is on the Singularity container. In general, files on the host system are not available to a container, i.e. we would not be able to process the data files with TreeSAPP! Luckily, we can to make the host directory with our data available to the container by creating a so-called bind path. Bind paths are defined by the environmental variable SINGULARITY_BIND which we will export (so it is also available to Singularity). Your home directories on both host and container will automatically be connected (i.e. whatever you save in the home directory of the container will be also available in the home directory of the host). Hint: Remember that you already defined a variable containing the path to the input directory. export &lt;bind paths variable name&gt;=&quot;&lt;shared directory&gt;&quot; 3.3.6 Creating output directory Define a variable for the TreeSAPP output directory and choose a name for it yourself. The directory should be located in your home directory (which is also shared between your host and container). To refer to your home directory, use the environmental variable HOME which is automatically defined by the shell (i.e. you do not need to first define it yourself). Finally, create the output directory. &lt;set output directory variable&gt; &lt;create the ouput directory&gt; 3.3.7 Reporting variables to user Let’s provide the user some feedback where TreeSAPP is going to save its output and what bind paths have been set. &lt;print command&gt; &quot;&lt;Some text explaining what variables have been set&gt;&quot; 3.3.8 Giving path to Singularity container with TreeSAPP Let’s define a variable with the path to the Singularity TreeSAPP container. &lt;variable for path to container&gt; 3.3.9 Listing TreeSAPP version In a previous tutorial we logged into the shell of the container (using singularity shell &lt;container name&gt;). One of the great advantages of containers is that we can directly execute commands on the container WITHOUT logging into it by using: singularity exec &lt;container name&gt; &lt;command that can be incredibly long depending on what you are doing&gt; Let’s print the information about the configuration of TreeSAPP using the command treesapp info on the container: echo &quot;The Singularity container at &lt;path to container&gt; has the following \\ configuration for TreeSAPP:&quot; &lt;execute command on container&gt; &lt;path to container&gt; treesapp info Hint: When we have very long commands in a script, we can introduce line breaks using \\ which are best used right after a space in the command (see example above after the word “following”). 3.3.10 Executing TreeSAPP analysis In CLI (i.e. not as part of this script), check the documentation for treesapp assign, the command you will use for the automated reconstruction of a nutrient cycle (visit its wikipage to learn more). Your command will look like this: &lt;execute command on treesapp container&gt; treesapp assign -h. Looking at the TreeSAPP documentation, determine the flags you need in addition to the ones already included below. Time to run our analysis! You will have to identify the input file(s) that you need to process. Your group has been assigned a specific depth, and you do only need to process any files of that depth (indicated in the name, e.g. SI072_135m_A_MetaT.fastq.gz is the metatranscriptome at 135 m depth). You will run the analysis once for metagenomic (two files, forward reads are in the file that contains .1 in its name, and reverse reads in file the with .2) and once for metatranscriptomic reads (a single file that contains both forward and reverse reads) and align them to the assembled contigs. All reads are pair-end. You will need to provide the following settings using flags: Which assembly file to use. To use 8 CPUs for the analysis. To do the analysis for all marker genes provided in TreeSAPP. To output a verbose runtime log. Where to save the results. To calculate the rpkm values for detected sequences. Which reads to use and what type they are (i.e. pair-end or single-end). To delete any intermediate files generated by the analysis. To use position masking of multiple sequence alignment. Hints: Will you ouput the data for metagenomic and metatranscriptomic analysis to the same folder? Does the folder already exist? If you want the default value of a flag, then you do not need to provide it. Where is the input data located in the singularity container? Metatrascriptomic reads are NOT rRNA. In scripts you often refer to variables while combined with additional text. Let’s say you have defined the variable file_name=\"some_file\" to refer to the file some_file. Now you want to save a modified version of the file as some_file_modified. If you would write $file_name_modified, then the shell does not know that you just want to call a variable called $file_name and instead will assume you are calling a variable called $file_name_modified and will return an empty string. To indicate the beginning and end of a variable name, use curly braces. In the above example, you would use ${file_name}_modified. Optional bonus challenge: Earlier we defined the depth variable. Could you use it in some way when you define which assembly and reads you are using in the analysis? # Metagenomic analysis singularity exec &lt;treesapp container&gt; \\ treesapp assign \\ -i &lt;input data dir&gt;&lt;file path to your assembly&gt; \\ -m &lt;choose the correct option&gt; \\ &lt;number of CPU threads, set to 8&gt; &lt;your output directory&gt; \\ &lt;your remaining settings&gt; # Metatranscriptomic analysis &lt;you are on your own now :)&gt; "],["R.html", "4 Analysing the TreeSAPP output in R 4.1 Resources for analysis of TreeSAPP output in R 4.2 Checklist to write and run R script 4.3 Writing the R script 4.4 Load any required packages 4.5 Load metagenomic and metatranscriptomic TreeSAPP data 4.6 Combine the metagenomic and metatranscriptomic data 4.7 Subset your data to the variables and marker genes of interest. 4.8 Processing taxonomic information 4.9 Load the geochemical data set into a new data frame. 4.10 Additional Hints for each guiding question", " 4 Analysing the TreeSAPP output in R These instructions will help you to complete the script template treesapp_analysis.R to complete the initial analysis of your TreeSAPP output. To adjust the code examples below and in the script template, replace any angle brackets, e.g. &lt;SOME TEXT&gt;, with the missing code. 4.1 Resources for analysis of TreeSAPP output in R Both TreeSAPP output files marker_contig_map.tsv (one each for the metagenomic and metatranscriptomic analysis) you generated on the Google Cloud Platform (GCP). An R script template called treesapp_analysis.R on Canvas. Saanich_Data.csv file containing geochemical measurements. 4.2 Checklist to write and run R script Place treesapp_analysis.R and both marker_contig_map.tsv files into a single folder and create a new RStudio project in that folder on your local computer. Edit the treesapp_analysis.R script following the instructions below. 4.3 Writing the R script In the treesapp_analysis.R script you will load and subset your TreeSAPP data to the variables and marker genes of interest. You will then combine the metagenomic and metatranscriptomic data into a single data frame and then break the taxonomic information into taxonomic ranks. You will also load the Saanich_Data.csv file for geochemical measurements to learn more about the conditions at your assigned depth. Further process your data sets to address the four main research questions. 4.4 Load any required packages &lt;Load packages&gt; 4.5 Load metagenomic and metatranscriptomic TreeSAPP data &lt;Load data sets&gt; 4.6 Combine the metagenomic and metatranscriptomic data Look at the documentation of rbind() on how to combine two data sets that contain the same variables. Before you do that, you should add a variable that tells you if a particular row comes from the metagenomic or metatranscriptomic source. &lt;Add variable to data frame indicating source&gt; &lt;Combine data sets&gt; 4.7 Subset your data to the variables and marker genes of interest. Determine which variables and marker genes you will need and subset your data to them. NarG is an ortholog of NxrA and cannot be distinguished by TreeSAPP. Any sequences that are identified as NxrA by TreeSAPP could be either NarG or NxrA. As a consequence, determine if your data contains NxrA as a marker. If your depth has anoxic conditions (O_2 &lt; 20 µM, true for all depths &lt;= 150 m), interpret NxrA assignments by TreeSAPP as NarG instead. &lt;If your depth is &lt;= 150, change &quot;NxrA&quot; entries to &quot;NarG&quot;&gt; &lt;Subset data&gt; 4.8 Processing taxonomic information Your taxonomic information contains information from the highest to lowest available rank. Look at a few rows containing taxonomic information anddetermine the separator between each rank. Google a function that allows you split a character object at each of these separator (Hint: there is a function in the tidyverse with that we did not cover). As a result, your initial single taxonomic variable will be split into multiple new variables, one for each rank. Use the R object rank to assign the names for those new variables. rank &lt;- c(&quot;root&quot;, &quot;kingdom&quot;, &quot;phylum&quot;, &quot;class&quot;, &quot;order&quot;, &quot;family&quot;, &quot;genus&quot;, &quot;species&quot;) &lt;split the taxonomic information in the data frame into separate ranks&gt; 4.9 Load the geochemical data set into a new data frame. &lt;Load geochemicals&gt; 4.10 Additional Hints for each guiding question 4.10.1 How does abundance of denitrification genes differ across the pathway? Are trends similar for both RNA and DNA? You will need to sum the abundance for each gene. What functions do you know that allow you to summarize data for multiple groups (in this case each marker gene constitutes a group). 4.10.2 How does microbial diversity differ across the pathway? Are trends similar for both RNA and DNA? You will need to make a decision at what taxonomic rank you will calculate diversity. Why might you not be able to use the lowest possible? Why should your taxonomic rank not be too high? You will need to calculate the total abundance for each taxon (for whichever rank you chose). What R package did you use before to calculate diversity? 4.10.3 What specific taxa are responsible for denitrification? Are they the same for all steps? For DNA versus RNA? You will need to count how many genes each taxa possess/expresses. 4.10.4 How does the abundance of denitrification genes relate to nitrogen species in Saanich (use the geochemical data in Saanich_Data.csv from our previous data science sessions)? Determine the geochemical conditions at your given depths. Which is the best available terminal electron acceptor? "],["references-1.html", "5 References", " 5 References "]]
